{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "os.chdir(\"../scripts/diffuser_icons/\")\n",
    "from dataset import *\n",
    "from config import ConditionalTrainingConfig\n",
    "from collections import Counter, defaultdict, OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 soda\n",
      "90 ('âˆ¦', 'DejaVuSans')\n"
     ]
    }
   ],
   "source": [
    "max_num_objs = 90\n",
    "with open(\"../../data/nouns/all_nouns.txt\", \"r\") as f:\n",
    "    nouns = [x.strip() for x in f.readlines()][:max_num_objs]\n",
    "print(len(nouns), nouns[0])\n",
    "with open(\"../../data/matplotlib/unicode.jsonl\", \"r\", encoding=\"unicode-escape\") as f: \n",
    "    icons = [(json.loads(x)[0], json.loads(x)[2]) for x in f.readlines()][:max_num_objs]\n",
    "print(len(icons), icons[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m fontsize \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m28\u001b[39m \u001b[38;5;66;03m#128\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#train_pairs, test_pairs = create_data_single_obj(nouns, icons, canvas_size=canvas_size, icon_size=icon_size, fontsize=fontsize)\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m train_pairs, test_pairs \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_data_split2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnouns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micon_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43micon_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfontsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(train_pairs), \u001b[38;5;28mlen\u001b[39m(test_pairs))\n",
      "File \u001b[0;32m~/workspace/clevr_control/scripts/diffuser_icons/dataset.py:118\u001b[0m, in \u001b[0;36mcreate_data_split2\u001b[0;34m(nouns, icons, canvas_size, icon_size, fontsize)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: B \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m_B\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m RELATIONS: \n\u001b[1;32m    116\u001b[0m         train_pairs\u001b[38;5;241m.\u001b[39mappend((\n\u001b[1;32m    117\u001b[0m             r\u001b[38;5;241m.\u001b[39mformat(A, B),\n\u001b[0;32m--> 118\u001b[0m             \u001b[43mdraw_icon\u001b[49m\u001b[43m(\u001b[49m\u001b[43municode1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43municode2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcanvas_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcanvas_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43micon_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43micon_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfontsize\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    119\u001b[0m         ))   \n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m j:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _A[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maeiuo\u001b[39m\u001b[38;5;124m'\u001b[39m: A \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m_A\n",
      "File \u001b[0;32m~/workspace/clevr_control/scripts/diffuser_icons/dataset.py:51\u001b[0m, in \u001b[0;36mdraw_icon\u001b[0;34m(unicode1, unicode2, canvas_size, icon_size, fontsize)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unicode2 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     50\u001b[0m     unicode_text2, font2 \u001b[38;5;241m=\u001b[39m unicode2\n\u001b[0;32m---> 51\u001b[0m     unicode_font2 \u001b[38;5;241m=\u001b[39m \u001b[43mImageFont\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtruetype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFONT_DIR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfont2\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.ttf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfontsize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     _, _, w, h \u001b[38;5;241m=\u001b[39m draw\u001b[38;5;241m.\u001b[39mtextbbox((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m), unicode_text2, font\u001b[38;5;241m=\u001b[39municode_font2)\n\u001b[1;32m     53\u001b[0m     draw\u001b[38;5;241m.\u001b[39mtext(((W\u001b[38;5;241m-\u001b[39mw)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m,(icon_size\u001b[38;5;241m-\u001b[39mh)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m+\u001b[39micon_size), unicode_text2, font\u001b[38;5;241m=\u001b[39municode_font2, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblack\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/workspace/clevr_control/venv/lib/python3.8/site-packages/PIL/ImageFont.py:797\u001b[0m, in \u001b[0;36mtruetype\u001b[0;34m(font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m FreeTypeFont(font, size, index, encoding, layout_engine)\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfreetype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    799\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_path(font):\n",
      "File \u001b[0;32m~/workspace/clevr_control/venv/lib/python3.8/site-packages/PIL/ImageFont.py:794\u001b[0m, in \u001b[0;36mtruetype.<locals>.freetype\u001b[0;34m(font)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfreetype\u001b[39m(font):\n\u001b[0;32m--> 794\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFreeTypeFont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/workspace/clevr_control/venv/lib/python3.8/site-packages/PIL/ImageFont.py:226\u001b[0m, in \u001b[0;36mFreeTypeFont.__init__\u001b[0;34m(self, font, size, index, encoding, layout_engine)\u001b[0m\n\u001b[1;32m    224\u001b[0m                 load_from_bytes(f)\n\u001b[1;32m    225\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 226\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfont \u001b[38;5;241m=\u001b[39m \u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetfont\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfont\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlayout_engine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayout_engine\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    230\u001b[0m     load_from_bytes(font)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "canvas_size = (32, 32) #(128, 128)\n",
    "icon_size = 32 #128\n",
    "fontsize = 28 #120\n",
    "#train_pairs, test_pairs = create_data_single_obj(nouns, icons, canvas_size=canvas_size, icon_size=icon_size, fontsize=fontsize)\n",
    "train_pairs, test_pairs = create_data_split2(nouns, icons, canvas_size=canvas_size, icon_size=icon_size, fontsize=fontsize)\n",
    "print(len(train_pairs), len(test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a soda is on top of a plant.\n"
     ]
    },
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCACAAIADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+iiigAooooAKKKKACiuP1r4p+DPDurz6Vqus/Z7232+bF9lmfblQw5VCDwR0Na3hrxbofi+0mutCvvtcEMnlyN5Tx4bGcYcA9DQBtUVi+JfFuh+ELSG612++yQTSeXG3lPJlsZxhAT0FZOi/FPwZ4i1eDStK1n7Re3G7yovssybsKWPLIAOAepoA7CiiigAooooAKKKKACiiigAooooAKKKKAPj741f8ld136wf+iI69X/Zt/wCRR1f/AK/x/wCi1ryj41f8ld136wf+iI69X/Zt/wCRR1f/AK/x/wCi1oAP2kv+RR0j/r/P/otq8o+Cv/JXdC+s/wD6Ikr1f9pL/kUdI/6/z/6LavKPgr/yV3QvrP8A+iJKAPsGiiigAooooAKKKKACiiigAooooAKKKKAPj741f8ld136wf+iI69X/AGbf+RR1f/r/AB/6LWvKPjV/yV3XfrB/6Ijr1f8AZt/5FHV/+v8AH/otaAD9pL/kUdI/6/z/AOi2ryj4K/8AJXdC+s//AKIkr1f9pL/kUdI/6/z/AOi2ryj4K/8AJXdC+s//AKIkoA+waKKKACiiigAooooAKKKKACiiigAooooA+PvjV/yV3XfrB/6Ijr1f9m3/AJFHV/8Ar/H/AKLWvKPjV/yV3XfrB/6Ijr1f9m3/AJFHV/8Ar/H/AKLWgA/aS/5FHSP+v8/+i2ryj4K/8ld0L6z/APoiSvV/2kv+RR0j/r/P/otq+edG1m/8P6rFqemT+ReQhxHKACV3KVJGe+GNAH3Ul1by3MttHPE88IUyxK4LIGztyOozg4z6VNXx/wDCzXPE1t8Q4LrSYLrU7i5bF9EWz5sZPzM7HgEdQxPX619gUAFFFFABRRRQAUUUUAFFFFABRRRQB8ffGr/kruu/WD/0RHXbfBvxtongr4f6xeavdBWa+/c26cyzHy14Vf6nAHrXBfF+8tr74q65cWk8c8JeJRJEwZSViRSMj0II/CuQsbC71O9isrG2lubmZtscUSlmY+wFAHXfEL4l6r4/vEFwiW2mwOWt7ROdp6bmbqzY+g9BWV4H8Nr4v8ZadoUlybZLpm3Squ4gKjOcD1IXH41u+MPhffeCPCFhqurXC/b7y58o2seCsK7SeW7twOnA9TR8Ff8AkruhfWf/ANESUAfU3hjwlo3g/SxYaNaLDHwZJDzJKfV27n9B2xW3RRQAUUUUAFFFFABRRRQAUUUUAFfL3xT+Luu6vf3vh+yhn0ixhkaGdGOJ5iDghiPur7Dr3Jr6hrgfFPwk8PeLfFdtruoCVWRNtzBEdoucY2lj1GBkHHJGORigD4+r6O/ZtsrX+wNXvjbxG7+1CITFRvCbFO3PXGTnFeUfF6ytdO+KOsWdlbxW9tCIFjiiUKqjyI+ABXr37Nv/ACKOr/8AX+P/AEWtAB+0l/yKOkf9f5/9FtXlHwV/5K7oX1n/APREler/ALSX/Io6R/1/n/0W1eUfBX/kruhfWf8A9ESUAfYNFFFABRRRQAUUUUAFFFFABRRRQAUUUUAfH3xq/wCSu679YP8A0RHXq/7Nv/Io6v8A9f4/9FrXlHxq/wCSu679YP8A0RHXq/7Nv/Io6v8A9f4/9FrQAftJf8ijpH/X+f8A0W1eUfBX/kruhfWf/wBESV6v+0l/yKOkf9f5/wDRbV5R8Ff+Su6F9Z//AERJQB9g0UUUAFFFFABRRRQAUUUUAFFFFABRRRQB8ffGr/kruu/WD/0RHXq/7Nv/ACKOr/8AX+P/AEWteUfGr/kruu/WD/0RHXq/7Nv/ACKOr/8AX+P/AEWtAB+0l/yKOkf9f5/9FtXlHwV/5K7oX1n/APREler/ALSX/Io6R/1/n/0W1eUfBX/kruhfWf8A9ESUAfYNFFFABRRRQAUUUUAf/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAIAAABMXPacAAAElElEQVR4Ae2cSyh0YRzGjSYLC2EnKZqFsnBZKVm4lYXdUMotFhIpJRYWFm4rCwsrUoxL7FhIIeW6EOWyZEM2SsJGCfn+vvkypzlzOfmaec5538fqeM+Zed7z+73POHNM4/r6+krgD45AIi6ayd8EKAC8DiiAAsAEwPFsAAWACYDj2QAKABMAx7MBFAAmAI5nAygATAAczwZQgInA8/OzK/zP2tqa6RH/BmRX+Me55GnDPRA4zgYA4X9HUwAFgAmA49kACgATAMezARQAJgCOZwMoAEwAHM8GUACYADieDaAAMAFwPBtAAWAC4Hg2gALABMDxbAAFgAmA49kACgATAMezARQAJgCOZwMoAEwAHM8GUACYADieDaAAMAFwPBtAAWAC4Hg2gALABMDxbAAFgAmA49kACgATAMezARQAJgCO17cB7+/vYPZ/43UU8PHxMTg4WFxc/Pb2BnegnYCrq6uSkpLR0dGzs7P+/n4KiCuB6enpoqKik5MTf+rk5OTGxkZcZ2AK06gBdXV1HR0dr6+vRgitra339/fGkThvayRgZ2fHDPfh4UEcAL+/WSMBZvr+kc3NzYmJiXB7Yz1OAd+E19fXUSXQXYDb7R4aGtre3pYvGor1Yg/5/O6Qo5oMejyepaUleUMAPF99G9DW1nZ+fo6lL+LVaYB8I9nc3JyVtZyeni5vCGpra60cHOtjFBGwt7fX3Nx8d3cXlVdlZaXP58vMzIx6ZHwOcPxLkNxTGxgYqKioiEo/KSlpfHxc/t7ah744dnYDrq+vGxoaTk9PrazW/f19+Cu+eZ4ObsDMzIzc2LFIX848NzfXfP7wEUc24PHxsb29fXV1FY7v/yfgvAbs7u7m5+erQV/8uVBvwSOsHbmgTEtLi3DA73Y9PT2lpqb+7rGxe5TzGhA7FpBnpgAI9kCoOgIKCwvHxsYCZ+aQLRUEyI3Mvr6+4+PjvLw8h2APTNORl6GB6SckZGVlya2F8vJy46CDtu3YgIuLC4sE6+vrLy8vnUtfTtNeAj4/P4eHh6uqqqIKSElJmZ+fX1lZseGVZdTJGw+w0UvQzc1NU1PT0dGRcX4ht0tLSxcWFrKzs0PuddagXRqwuLhYUFBghX5PT4/cfFaDvqwVfANeXl46OzuXl5ctrtyysrLERLusG4tzjnAYWMDBwYH8I+X29jbCFNXeBVtK/k/IygWMzvRlbcEaUFNTs7W1pfbqtnJ2sAY0NjZamZ/yx8AEtLS0yKdllecb9QRhAmRmU1NTGRkZQVOUK5zu7u6gQYV/RQqQz+fMzs4a4ebk5Mg1/sjIiHFQ7W2kACFbXV3d1dXlRywfE5e7QPIuV23iQWcHuwr6mYd8Vke49/b2er3en0F9NvACkpOTDw8P9SEedKbgl6Cg2Wj4KwWApVMABYAJgOPZAAoAEwDHswEUACYAjmcDKABMABzPBlAAmAA4ng2gADABcDwbQAFgAuB4NoACwATA8WwABYAJgOPZAAoAEwDHswEUACYAjmcDKABMABzPBlAAmAA4ng2gADABcDwbQAFgAuB4NoACwATA8WwAWMAfaFTtmaJqUZEAAAAASUVORK5CYII=",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 84\n",
    "print(train_pairs[k][0])\n",
    "train_pairs[k][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9460\n"
     ]
    }
   ],
   "source": [
    "# gather concept freqeucies\n",
    "def extract_two_concepts(s):\n",
    "    t = s.replace(\".\", \"\").split()\n",
    "    return t[1], t[-1]\n",
    "c = Counter([w for x in train_pairs for w in extract_two_concepts(x[0])])\n",
    "total_freq = sum(c.values())\n",
    "print(total_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1QAAAFfCAYAAABJOY23AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8WgzjOAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxrUlEQVR4nO3df1TVdZ7H8RegcP2JBiNXjYQpNzTxFyZBzNhuHKA4a3dzGLUSZBhtC/LHPVnpIrhSkpqGP5hhbMTslCuxa46Wy0Y02s6Kv1CmtHSy0cHCi7qO0tIICt/9w+O37nBB7nc0zJ6Pcz4H7+fz/n6+ny/nM6d5ne/3fvExDMMQAAAAAMBrvp29AAAAAAD4riJQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIu6dPYCbiQtLS2qra1Vr1695OPj09nLAQAAANBJDMPQl19+qQEDBsjXt+37UASqb6itrVVoaGhnLwMAAADADeLEiRO69dZb2xwnUH1Dr169JF3+pfXu3buTVwMAAACgs9TX1ys0NNTMCG0hUH3Dlcf8evfuTaACAAAAcNWvAvFSCgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABY1KWzF4C2hT33jtvn4y8m37Dj13puAAAA4LuAO1QAAAAAYBGBCgAAAAAsIlABAAAAgEUEKgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIssBarCwkKFhYXJZrMpOjpae/bsabe+tLRUERERstlsioyM1LZt29zGN23apISEBAUFBcnHx0fV1dVu48ePH5ePj4/HVlpaatZ5Gt+4caOVSwQAAACAq/I6UJWUlMjpdCo3N1f79+/XiBEjlJiYqFOnTnms37lzpyZPnqyMjAwdOHBADodDDodDBw8eNGsaGhoUFxenxYsXe5wjNDRUJ0+edGv/+q//qp49e+qBBx5wq123bp1bncPh8PYSAQAAAKBDunh7wPLlyzVt2jSlp6dLkoqKivTOO++ouLhYzz33XKv6FStWKCkpSXPmzJEk5eXlqby8XKtXr1ZRUZEkacqUKZIu34nyxM/PT3a73a3vrbfe0k9/+lP17NnTrb9Pnz6tatvS2NioxsZG83N9fX2HjgMAAAAAycs7VE1NTaqqqlJ8fPzXE/j6Kj4+XpWVlR6PqaysdKuXpMTExDbrO6KqqkrV1dXKyMhoNZaZmang4GCNHTtWxcXFMgyjzXny8/MVGBhottDQUMtrAgAAAPD941WgOnPmjJqbmxUSEuLWHxISIpfL5fEYl8vlVX1HrF27VkOGDFFsbKxb/8KFC/Xmm2+qvLxcEyZM0JNPPqlVq1a1Oc/cuXN1/vx5s504ccLymgAAAAB8/3j9yF9n+8tf/qINGzZo/vz5rca+2Tdq1Cg1NDRo6dKlmjFjhse5AgICFBAQcN3WCgAAAODm5tUdquDgYPn5+amurs6tv66urs3vLdntdq/qr+bf//3f9dVXXyk1NfWqtdHR0fr888/dvicFAAAAANeKV4HK399fUVFRqqioMPtaWlpUUVGhmJgYj8fExMS41UtSeXl5m/VXs3btWo0fP14/+MEPrlpbXV2tvn37chcKAAAAwHXh9SN/TqdTaWlpGjNmjMaOHauCggI1NDSYb/1LTU3VwIEDlZ+fL0maOXOmxo0bp2XLlik5OVkbN27Uvn37tGbNGnPOs2fPqqamRrW1tZKkI0eOSLp8d+ubd7KOHj2qDz74oNXfsZKkrVu3qq6uTvfcc49sNpvKy8u1aNEiPf30095eIgAAAAB0iNeBauLEiTp9+rRycnLkcrk0cuRIlZWVmS+eqKmpka/v1ze+YmNjtWHDBmVnZ2vevHkaPHiwNm/erGHDhpk1W7ZsMQOZJE2aNEmSlJubqwULFpj9xcXFuvXWW5WQkNBqXV27dlVhYaFmz54twzB0xx13mK94BwAAAIDrwdJLKbKyspSVleVxbPv27a36UlJSlJKS0uZ8U6dO1dSpU6963kWLFmnRokUex5KSkpSUlHTVOQAAAADgWvHqO1QAAAAAgK8RqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIsIVAAAAABgEYEKAAAAACwiUAEAAACARQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQAAAAAYBGBCgAAAAAsIlABAAAAgEUEKgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiywFqsLCQoWFhclmsyk6Olp79uxpt760tFQRERGy2WyKjIzUtm3b3MY3bdqkhIQEBQUFycfHR9XV1a3muO++++Tj4+PW/vmf/9mtpqamRsnJyerevbv69eunOXPm6NKlS1YuEQAAAACuyutAVVJSIqfTqdzcXO3fv18jRoxQYmKiTp065bF+586dmjx5sjIyMnTgwAE5HA45HA4dPHjQrGloaFBcXJwWL17c7rmnTZumkydPmm3JkiXmWHNzs5KTk9XU1KSdO3dq/fr1evXVV5WTk+PtJQIAAABAh3gdqJYvX65p06YpPT1dQ4cOVVFRkbp3767i4mKP9StWrFBSUpLmzJmjIUOGKC8vT6NHj9bq1avNmilTpignJ0fx8fHtnrt79+6y2+1m6927tzn27rvv6uOPP9brr7+ukSNH6oEHHlBeXp4KCwvV1NTkcb7GxkbV19e7NQAAAADoKK8CVVNTk6qqqtyCj6+vr+Lj41VZWenxmMrKylZBKTExsc369rzxxhsKDg7WsGHDNHfuXH311Vdu54mMjFRISIjbeerr63Xo0CGP8+Xn5yswMNBsoaGhXq8JAAAAwPdXF2+Kz5w5o+bmZrfQIkkhISE6fPiwx2NcLpfHepfL5dVCH3nkEQ0aNEgDBgzQhx9+qGeffVZHjhzRpk2b2j3PlTFP5s6dK6fTaX6ur68nVAEAAADoMK8CVWeaPn26+e/IyEj1799f999/vz777DPdfvvtluYMCAhQQEDAtVoiAAAAgO8Zrx75Cw4Olp+fn+rq6tz66+rqZLfbPR5jt9u9qu+o6OhoSdLRo0fbPc+VMQAAAAC41rwKVP7+/oqKilJFRYXZ19LSooqKCsXExHg8JiYmxq1eksrLy9us76grr1bv37+/eZ6PPvrI7W2D5eXl6t27t4YOHfo3nQsAAAAAPPH6kT+n06m0tDSNGTNGY8eOVUFBgRoaGpSeni5JSk1N1cCBA5Wfny9JmjlzpsaNG6dly5YpOTlZGzdu1L59+7RmzRpzzrNnz6qmpka1tbWSpCNHjkiS+Ta/zz77TBs2bNCDDz6ooKAgffjhh5o9e7Z+/OMfa/jw4ZKkhIQEDR06VFOmTNGSJUvkcrmUnZ2tzMxMHusDAAAAcF14HagmTpyo06dPKycnRy6XSyNHjlRZWZn5Aoiamhr5+n594ys2NlYbNmxQdna25s2bp8GDB2vz5s0aNmyYWbNlyxYzkEnSpEmTJEm5ublasGCB/P399d5775nhLTQ0VBMmTFB2drZ5jJ+fn95++2098cQTiomJUY8ePZSWlqaFCxd6/1sBAAAAgA6w9FKKrKwsZWVleRzbvn17q76UlBSlpKS0Od/UqVM1derUNsdDQ0O1Y8eOq65r0KBB2rZt21XrAAAAAOBa8PoP+wIAAAAALiNQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIsIVAAAAABgEYEKAAAAACwiUAEAAACARQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQAAAAAYBGBCgAAAAAsIlABAAAAgEUEKgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWWQpUhYWFCgsLk81mU3R0tPbs2dNufWlpqSIiImSz2RQZGalt27a5jW/atEkJCQkKCgqSj4+Pqqur3cbPnj2rp556Snfeeae6deum2267TTNmzND58+fd6nx8fFq1jRs3WrlEAAAAALgqrwNVSUmJnE6ncnNztX//fo0YMUKJiYk6deqUx/qdO3dq8uTJysjI0IEDB+RwOORwOHTw4EGzpqGhQXFxcVq8eLHHOWpra1VbW6uXXnpJBw8e1KuvvqqysjJlZGS0ql23bp1OnjxpNofD4e0lAgAAAECHdPH2gOXLl2vatGlKT0+XJBUVFemdd95RcXGxnnvuuVb1K1asUFJSkubMmSNJysvLU3l5uVavXq2ioiJJ0pQpUyRJx48f93jOYcOG6T/+4z/Mz7fffrteeOEFPfbYY7p06ZK6dPn6Mvr06SO73d6ha2lsbFRjY6P5ub6+vkPHAQAAAIDk5R2qpqYmVVVVKT4+/usJfH0VHx+vyspKj8dUVla61UtSYmJim/Uddf78efXu3dstTElSZmamgoODNXbsWBUXF8swjDbnyM/PV2BgoNlCQ0P/pjUBAAAA+H7xKlCdOXNGzc3NCgkJcesPCQmRy+XyeIzL5fKqvqPryMvL0/Tp0936Fy5cqDfffFPl5eWaMGGCnnzySa1atarNeebOnavz58+b7cSJE5bXBAAAAOD7x+tH/jpbfX29kpOTNXToUC1YsMBtbP78+ea/R40apYaGBi1dulQzZszwOFdAQIACAgKu53IBAAAA3MS8ukMVHBwsPz8/1dXVufXX1dW1+b0lu93uVX17vvzySyUlJalXr15666231LVr13bro6Oj9fnnn7t9TwoAAAAArhWvApW/v7+ioqJUUVFh9rW0tKiiokIxMTEej4mJiXGrl6Ty8vI269tSX1+vhIQE+fv7a8uWLbLZbFc9prq6Wn379uUuFAAAAIDrwutH/pxOp9LS0jRmzBiNHTtWBQUFamhoMN/6l5qaqoEDByo/P1+SNHPmTI0bN07Lli1TcnKyNm7cqH379mnNmjXmnGfPnlVNTY1qa2slSUeOHJF0+e6W3W43w9RXX32l119/XfX19eYb+X7wgx/Iz89PW7duVV1dne655x7ZbDaVl5dr0aJFevrpp/+23xAAAAAAtMHrQDVx4kSdPn1aOTk5crlcGjlypMrKyswXT9TU1MjX9+sbX7GxsdqwYYOys7M1b948DR48WJs3b9awYcPMmi1btpiBTJImTZokScrNzdWCBQu0f/9+7d69W5J0xx13uK3n2LFjCgsLU9euXVVYWKjZs2fLMAzdcccd5iveAQAAAOB6sPRSiqysLGVlZXkc2759e6u+lJQUpaSktDnf1KlTNXXq1DbH77vvvnZffy5JSUlJSkpKarcGAAAAAK4lr75DBQAAAAD4GoEKAAAAACwiUAEAAACARQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQAAAAAYBGBCgAAAAAsIlABAAAAgEUEKgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIsIVAAAAABgEYEKAAAAACzq0tkLADwJe+4dt8/HX0y+Ycdv5LVd7/EbeW3XevxGXtv1Hr+R13a9x2/ktV3r8Rt5bdd7/EZe27Uev5HXdr3Hb+S1Xe/xG3ltHRm/0XGHCgAAAAAsshSoCgsLFRYWJpvNpujoaO3Zs6fd+tLSUkVERMhmsykyMlLbtm1zG9+0aZMSEhIUFBQkHx8fVVdXt5rjwoULyszMVFBQkHr27KkJEyaorq7OraampkbJycnq3r27+vXrpzlz5ujSpUtWLhEAAAAArsrrQFVSUiKn06nc3Fzt379fI0aMUGJiok6dOuWxfufOnZo8ebIyMjJ04MABORwOORwOHTx40KxpaGhQXFycFi9e3OZ5Z8+era1bt6q0tFQ7duxQbW2tHn74YXO8ublZycnJampq0s6dO7V+/Xq9+uqrysnJ8fYSAQAAAKBDvA5Uy5cv17Rp05Senq6hQ4eqqKhI3bt3V3Fxscf6FStWKCkpSXPmzNGQIUOUl5en0aNHa/Xq1WbNlClTlJOTo/j4eI9znD9/XmvXrtXy5cv1D//wD4qKitK6deu0c+dO7dq1S5L07rvv6uOPP9brr7+ukSNH6oEHHlBeXp4KCwvV1NTkcd7GxkbV19e7NQAAAADoKK8CVVNTk6qqqtyCj6+vr+Lj41VZWenxmMrKylZBKTExsc16T6qqqnTx4kW3eSIiInTbbbeZ81RWVioyMlIhISFu56mvr9ehQ4c8zpufn6/AwECzhYaGdnhNAAAAAOBVoDpz5oyam5vdQoskhYSEyOVyeTzG5XJ5Vd/WHP7+/urTp0+b87R1nitjnsydO1fnz58324kTJzq8JgAAAAD4Xr82PSAgQAEBAZ29DAAAAADfUV7doQoODpafn1+rt+vV1dXJbrd7PMZut3tV39YcTU1NOnfuXJvztHWeK2MAAAAAcK15Faj8/f0VFRWliooKs6+lpUUVFRWKiYnxeExMTIxbvSSVl5e3We9JVFSUunbt6jbPkSNHVFNTY84TExOjjz76yO1tg+Xl5erdu7eGDh3a4XMBAAAAQEd5/cif0+lUWlqaxowZo7Fjx6qgoEANDQ1KT0+XJKWmpmrgwIHKz8+XJM2cOVPjxo3TsmXLlJycrI0bN2rfvn1as2aNOefZs2dVU1Oj2tpaSZfDknT5zpLdbldgYKAyMjLkdDp1yy23qHfv3nrqqacUExOje+65R5KUkJCgoUOHasqUKVqyZIlcLpeys7OVmZnJY30AAAAArguvA9XEiRN1+vRp5eTkyOVyaeTIkSorKzNfAFFTUyNf369vfMXGxmrDhg3Kzs7WvHnzNHjwYG3evFnDhg0za7Zs2WIGMkmaNGmSJCk3N1cLFiyQJL388svy9fXVhAkT1NjYqMTERP3iF78wj/Hz89Pbb7+tJ554QjExMerRo4fS0tK0cOFCby8RAAAAADrE0kspsrKylJWV5XFs+/btrfpSUlKUkpLS5nxTp07V1KlT2z2nzWZTYWGhCgsL26wZNGiQtm3b1u48AAAAAHCteP2HfQEAAAAAlxGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQAAAAAYBGBCgAAAAAsIlABAAAAgEUEKgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIsIVAAAAABgEYEKAAAAACwiUAEAAACARQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiAhUAAAAAWESgAgAAAACLLAWqwsJChYWFyWazKTo6Wnv27Gm3vrS0VBEREbLZbIqMjNS2bdvcxg3DUE5Ojvr3769u3bopPj5en376qTm+fft2+fj4eGx79+6VJB0/ftzj+K5du6xcIgAAAABcldeBqqSkRE6nU7m5udq/f79GjBihxMREnTp1ymP9zp07NXnyZGVkZOjAgQNyOBxyOBw6ePCgWbNkyRKtXLlSRUVF2r17t3r06KHExERduHBBkhQbG6uTJ0+6tZ///OcKDw/XmDFj3M733nvvudVFRUV5e4kAAAAA0CFeB6rly5dr2rRpSk9P19ChQ1VUVKTu3buruLjYY/2KFSuUlJSkOXPmaMiQIcrLy9Po0aO1evVqSZfvThUUFCg7O1sPPfSQhg8frtdee021tbXavHmzJMnf3192u91sQUFB+s1vfqP09HT5+Pi4nS8oKMittmvXrm1eS2Njo+rr690aAAAAAHSUV4GqqalJVVVVio+P/3oCX1/Fx8ersrLS4zGVlZVu9ZKUmJho1h87dkwul8utJjAwUNHR0W3OuWXLFv3v//6v0tPTW42NHz9e/fr1U1xcnLZs2dLu9eTn5yswMNBsoaGh7dYDAAAAwDd5FajOnDmj5uZmhYSEuPWHhITI5XJ5PMblcrVbf+WnN3OuXbtWiYmJuvXWW82+nj17atmyZSotLdU777yjuLg4ORyOdkPV3Llzdf78ebOdOHGizVoAAAAA+GtdOnsB3vr888/1X//1X3rzzTfd+oODg+V0Os3Pd999t2pra7V06VKNHz/e41wBAQEKCAi4rusFAAAAcPPy6g5VcHCw/Pz8VFdX59ZfV1cnu93u8Ri73d5u/ZWfHZ1z3bp1CgoKajMkfVN0dLSOHj161ToAAAAAsMKrQOXv76+oqChVVFSYfS0tLaqoqFBMTIzHY2JiYtzqJam8vNysDw8Pl91ud6upr6/X7t27W81pGIbWrVun1NTUdl82cUV1dbX69+/f4esDAAAAAG94/cif0+lUWlqaxowZo7Fjx6qgoEANDQ3mCyJSU1M1cOBA5efnS5JmzpypcePGadmyZUpOTtbGjRu1b98+rVmzRpLk4+OjWbNm6fnnn9fgwYMVHh6u+fPna8CAAXI4HG7nfv/993Xs2DH9/Oc/b7Wu9evXy9/fX6NGjZIkbdq0ScXFxfr1r3/t7SUCAAAAQId4HagmTpyo06dPKycnRy6XSyNHjlRZWZn5Uomamhr5+n594ys2NlYbNmxQdna25s2bp8GDB2vz5s0aNmyYWfPMM8+ooaFB06dP17lz5xQXF6eysjLZbDa3c69du1axsbGKiIjwuLa8vDz96U9/UpcuXRQREaGSkhL95Cc/8fYSAQAAAKBDLL2UIisrS1lZWR7Htm/f3qovJSVFKSkpbc7n4+OjhQsXauHChe2ed8OGDW2OpaWlKS0trd3jAQAAAOBa8voP+wIAAAAALiNQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIsIVAAAAABgEYEKAAAAACwiUAEAAACARQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQAAAAAYBGBCgAAAAAsIlABAAAAgEUEKgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWWQpUhYWFCgsLk81mU3R0tPbs2dNufWlpqSIiImSz2RQZGalt27a5jRuGoZycHPXv31/dunVTfHy8Pv30U7easLAw+fj4uLUXX3zRrebDDz/Uj370I9lsNoWGhmrJkiVWLg8AAAAAOsTrQFVSUiKn06nc3Fzt379fI0aMUGJiok6dOuWxfufOnZo8ebIyMjJ04MABORwOORwOHTx40KxZsmSJVq5cqaKiIu3evVs9evRQYmKiLly44DbXwoULdfLkSbM99dRT5lh9fb0SEhI0aNAgVVVVaenSpVqwYIHWrFnj7SUCAAAAQId4HaiWL1+uadOmKT09XUOHDlVRUZG6d++u4uJij/UrVqxQUlKS5syZoyFDhigvL0+jR4/W6tWrJV2+O1VQUKDs7Gw99NBDGj58uF577TXV1tZq8+bNbnP16tVLdrvdbD169DDH3njjDTU1Nam4uFh33XWXJk2apBkzZmj58uVtXktjY6Pq6+vdGgAAAAB0lFeBqqmpSVVVVYqPj/96Al9fxcfHq7Ky0uMxlZWVbvWSlJiYaNYfO3ZMLpfLrSYwMFDR0dGt5nzxxRcVFBSkUaNGaenSpbp06ZLbeX784x/L39/f7TxHjhzRn//8Z49ry8/PV2BgoNlCQ0M7+JsAAAAAAC8D1ZkzZ9Tc3KyQkBC3/pCQELlcLo/HuFyuduuv/LzanDNmzNDGjRv129/+Vo8//rgWLVqkZ5555qrn+eY5/trcuXN1/vx5s504caLNawcAAACAv9alsxfQUU6n0/z38OHD5e/vr8cff1z5+fkKCAiwNGdAQIDlYwEAAADAqztUwcHB8vPzU11dnVt/XV2d7Ha7x2Psdnu79Vd+ejOnJEVHR+vSpUs6fvx4u+f55jkAAAAA4FryKlD5+/srKipKFRUVZl9LS4sqKioUExPj8ZiYmBi3ekkqLy8368PDw2W3291q6uvrtXv37jbnlKTq6mr5+vqqX79+5nk++OADXbx40e08d955p/r27evNZQIAAABAh3j9lj+n06lXXnlF69ev1yeffKInnnhCDQ0NSk9PlySlpqZq7ty5Zv3MmTNVVlamZcuW6fDhw1qwYIH27dunrKwsSZKPj49mzZql559/Xlu2bNFHH32k1NRUDRgwQA6HQ9LlF04UFBTo97//vf74xz/qjTfe0OzZs/XYY4+ZYemRRx6Rv7+/MjIydOjQIZWUlGjFihVujwoCAAAAwLXk9XeoJk6cqNOnTysnJ0cul0sjR45UWVmZ+QKImpoa+fp+ndNiY2O1YcMGZWdna968eRo8eLA2b96sYcOGmTXPPPOMGhoaNH36dJ07d05xcXEqKyuTzWaTdPm7Ths3btSCBQvU2Nio8PBwzZ492y0sBQYG6t1331VmZqaioqIUHBysnJwcTZ8+3fIvBwAAAADaY+mlFFlZWeYdpr+2ffv2Vn0pKSlKSUlpcz4fHx8tXLhQCxcu9Dg+evRo7dq166rrGj58uP77v//7qnUAAAAAcC14/cgfAAAAAOAyAhUAAAAAWESgAgAAAACLCFQAAAAAYBGBCgAAAAAsIlABAAAAgEUEKgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIsIVAAAAABgEYEKAAAAACwiUAEAAACARQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQAAAAAYJGlQFVYWKiwsDDZbDZFR0drz5497daXlpYqIiJCNptNkZGR2rZtm9u4YRjKyclR//791a1bN8XHx+vTTz81x48fP66MjAyFh4erW7duuv3225Wbm6umpia3Gh8fn1Zt165dVi4RAAAAAK7K60BVUlIip9Op3Nxc7d+/XyNGjFBiYqJOnTrlsX7nzp2aPHmyMjIydODAATkcDjkcDh08eNCsWbJkiVauXKmioiLt3r1bPXr0UGJioi5cuCBJOnz4sFpaWvSrX/1Khw4d0ssvv6yioiLNmzev1fnee+89nTx50mxRUVHeXiIAAAAAdIjXgWr58uWaNm2a0tPTNXToUBUVFal79+4qLi72WL9ixQolJSVpzpw5GjJkiPLy8jR69GitXr1a0uW7UwUFBcrOztZDDz2k4cOH67XXXlNtba02b94sSUpKStK6deuUkJCgH/7whxo/fryefvppbdq0qdX5goKCZLfbzda1a9c2r6WxsVH19fVuDQAAAAA6yqtA1dTUpKqqKsXHx389ga+v4uPjVVlZ6fGYyspKt3pJSkxMNOuPHTsml8vlVhMYGKjo6Og255Sk8+fP65ZbbmnVP378ePXr109xcXHasmVLu9eTn5+vwMBAs4WGhrZbDwAAAADf5FWgOnPmjJqbmxUSEuLWHxISIpfL5fEYl8vVbv2Vn97MefToUa1atUqPP/642dezZ08tW7ZMpaWleueddxQXFyeHw9FuqJo7d67Onz9vthMnTrRZCwAAAAB/rUtnL8BbX3zxhZKSkpSSkqJp06aZ/cHBwXI6nebnu+++W7W1tVq6dKnGjx/vca6AgAAFBARc9zUDAAAAuDl5dYcqODhYfn5+qqurc+uvq6uT3W73eIzdbm+3/srPjsxZW1urv//7v1dsbKzWrFlz1fVGR0fr6NGjV60DAAAAACu8ClT+/v6KiopSRUWF2dfS0qKKigrFxMR4PCYmJsatXpLKy8vN+vDwcNntdrea+vp67d69223OL774Qvfdd5+ioqK0bt06+fpefenV1dXq37+/N5cIAAAAAB3m9SN/TqdTaWlpGjNmjMaOHauCggI1NDQoPT1dkpSamqqBAwcqPz9fkjRz5kyNGzdOy5YtU3JysjZu3Kh9+/aZd5h8fHw0a9YsPf/88xo8eLDCw8M1f/58DRgwQA6HQ9LXYWrQoEF66aWXdPr0aXM9V+5irV+/Xv7+/ho1apQkadOmTSouLtavf/1r678dAAAAAGiH14Fq4sSJOn36tHJycuRyuTRy5EiVlZWZL5Woqalxu3sUGxurDRs2KDs7W/PmzdPgwYO1efNmDRs2zKx55pln1NDQoOnTp+vcuXOKi4tTWVmZbDabpMt3tI4ePaqjR4/q1ltvdVuPYRjmv/Py8vSnP/1JXbp0UUREhEpKSvSTn/zE20sEAAAAgA6x9FKKrKwsZWVleRzbvn17q76UlBSlpKS0OZ+Pj48WLlyohQsXehyfOnWqpk6d2u6a0tLSlJaW1m4NAAAAAFxLXv9hXwAAAADAZQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQAAAAAYBGBCgAAAAAsIlABAAAAgEUEKgAAAACwiEAFAAAAABYRqAAAAADAIgIVAAAAAFhEoAIAAAAAiwhUAAAAAGARgQoAAAAALCJQAQAAAIBFBCoAAAAAsIhABQAAAAAWEagAAAAAwCICFQAAAABYRKACAAAAAIsIVAAAAABgEYEKAAAAACwiUAEAAACARQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiS4GqsLBQYWFhstlsio6O1p49e9qtLy0tVUREhGw2myIjI7Vt2za3ccMwlJOTo/79+6tbt26Kj4/Xp59+6lZz9uxZPfroo+rdu7f69OmjjIwM/d///Z9bzYcffqgf/ehHstlsCg0N1ZIlS6xcHgAAAAB0iNeBqqSkRE6nU7m5udq/f79GjBihxMREnTp1ymP9zp07NXnyZGVkZOjAgQNyOBxyOBw6ePCgWbNkyRKtXLlSRUVF2r17t3r06KHExERduHDBrHn00Ud16NAhlZeX6+2339YHH3yg6dOnm+P19fVKSEjQoEGDVFVVpaVLl2rBggVas2aNt5cIAAAAAB3SxdsDli9frmnTpik9PV2SVFRUpHfeeUfFxcV67rnnWtWvWLFCSUlJmjNnjiQpLy9P5eXlWr16tYqKimQYhgoKCpSdna2HHnpIkvTaa68pJCREmzdv1qRJk/TJJ5+orKxMe/fu1ZgxYyRJq1at0oMPPqiXXnpJAwYM0BtvvKGmpiYVFxfL399fd911l6qrq7V8+XK34PVNjY2NamxsND+fP39e0uVwdiNoafzK7fNfr+tGGr+R13a9x2/ktV3v8Rt5bdd6/EZe2/Uev5HXdr3Hb+S1XevxG3lt13v8Rl7btR6/kdd2vcdv5LVd7/EbeW0dGe8sV9ZhGEb7hYYXGhsbDT8/P+Ott95y609NTTXGjx/v8ZjQ0FDj5ZdfduvLyckxhg8fbhiGYXz22WeGJOPAgQNuNT/+8Y+NGTNmGIZhGGvXrjX69OnjNn7x4kXDz8/P2LRpk2EYhjFlyhTjoYcecqt5//33DUnG2bNnPa4tNzfXkESj0Wg0Go1Go9FoHtuJEyfaikeGYRiGV3eozpw5o+bmZoWEhLj1h4SE6PDhwx6PcblcHutdLpc5fqWvvZp+/fq5jXfp0kW33HKLW014eHirOa6M9e3bt9Xa5s6dK6fTaX5uaWnR2bNnFRQUJB8fH4/X822rr69XaGioTpw4od69e3f2cvA9wb7Dt409h28bew6dgX333WIYhr788ksNGDCg3TqvH/m7mQQEBCggIMCtr0+fPp2zmKvo3bs3/8PDt459h28bew7fNvYcOgP77rsjMDDwqjVevZQiODhYfn5+qqurc+uvq6uT3W73eIzdbm+3/srPq9X89UsvLl26pLNnz7rVeJrjm+cAAAAAgGvJq0Dl7++vqKgoVVRUmH0tLS2qqKhQTEyMx2NiYmLc6iWpvLzcrA8PD5fdbnerqa+v1+7du82amJgYnTt3TlVVVWbN+++/r5aWFkVHR5s1H3zwgS5evOh2njvvvNPj434AAAAA8Lfy+rXpTqdTr7zyitavX69PPvlETzzxhBoaGsy3/qWmpmru3Llm/cyZM1VWVqZly5bp8OHDWrBggfbt26esrCxJko+Pj2bNmqXnn39eW7Zs0UcffaTU1FQNGDBADodDkjRkyBAlJSVp2rRp2rNnj/7nf/5HWVlZmjRpkvlM4yOPPCJ/f39lZGTo0KFDKikp0YoVK9y+I/VdFBAQoNzc3FaPJgLXE/sO3zb2HL5t7Dl0BvbdzcnHMK72HsDWVq9eraVLl8rlcmnkyJFauXKleafovvvuU1hYmF599VWzvrS0VNnZ2Tp+/LgGDx6sJUuW6MEHHzTHDcNQbm6u1qxZo3PnzikuLk6/+MUv9Hd/93dmzdmzZ5WVlaWtW7fK19dXEyZM0MqVK9WzZ0+z5sMPP1RmZqb27t2r4OBgPfXUU3r22Wet/F4AAAAA4KosBSoAAAAAgIVH/gAAAAAAlxGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQ3uMLCQoWFhclmsyk6Olp79uzp7CXhJpGfn6+7775bvXr1Ur9+/eRwOHTkyBG3mgsXLigzM1NBQUHq2bOnJkyY0OoPaANWvfjii+afzriCPYfr4YsvvtBjjz2moKAgdevWTZGRkdq3b585bhiGcnJy1L9/f3Xr1k3x8fH69NNPO3HF+C5rbm7W/PnzFR4erm7duun2229XXl6evvkeOPbczYVAdQMrKSmR0+lUbm6u9u/frxEjRigxMVGnTp3q7KXhJrBjxw5lZmZq165dKi8v18WLF5WQkKCGhgazZvbs2dq6datKS0u1Y8cO1dbW6uGHH+7EVeNmsXfvXv3qV7/S8OHD3frZc7jW/vznP+vee+9V165d9Z//+Z/6+OOPtWzZMvXt29esWbJkiVauXKmioiLt3r1bPXr0UGJioi5cuNCJK8d31eLFi/XLX/5Sq1ev1ieffKLFixdryZIlWrVqlVnDnrvJGLhhjR071sjMzDQ/Nzc3GwMGDDDy8/M7cVW4WZ06dcqQZOzYscMwDMM4d+6c0bVrV6O0tNSs+eSTTwxJRmVlZWctEzeBL7/80hg8eLBRXl5ujBs3zpg5c6ZhGOw5XB/PPvusERcX1+Z4S0uLYbfbjaVLl5p9586dMwICAox/+7d/+zaWiJtMcnKy8bOf/cyt7+GHHzYeffRRwzDYczcj7lDdoJqamlRVVaX4+Hizz9fXV/Hx8aqsrOzEleFmdf78eUnSLbfcIkmqqqrSxYsX3fZgRESEbrvtNvYg/iaZmZlKTk5221sSew7Xx5YtWzRmzBilpKSoX79+GjVqlF555RVz/NixY3K5XG77LjAwUNHR0ew7WBIbG6uKigr94Q9/kCT9/ve/1+9+9zs98MADkthzN6Munb0AeHbmzBk1NzcrJCTErT8kJESHDx/upFXhZtXS0qJZs2bp3nvv1bBhwyRJLpdL/v7+6tOnj1ttSEiIXC5XJ6wSN4ONGzdq//792rt3b6sx9hyuhz/+8Y/65S9/KafTqXnz5mnv3r2aMWOG/P39lZaWZu4tT/+9Zd/Biueee0719fWKiIiQn5+fmpub9cILL+jRRx+VJPbcTYhABUCZmZk6ePCgfve733X2UnATO3HihGbOnKny8nLZbLbOXg6+J1paWjRmzBgtWrRIkjRq1CgdPHhQRUVFSktL6+TV4Wb05ptv6o033tCGDRt01113qbq6WrNmzdKAAQPYczcpHvm7QQUHB8vPz6/V263q6upkt9s7aVW4GWVlZentt9/Wb3/7W916661mv91uV1NTk86dO+dWzx6EVVVVVTp16pRGjx6tLl26qEuXLtqxY4dWrlypLl26KCQkhD2Ha65///4aOnSoW9+QIUNUU1MjSebe4r+3uFbmzJmj5557TpMmTVJkZKSmTJmi2bNnKz8/XxJ77mZEoLpB+fv7KyoqShUVFWZfS0uLKioqFBMT04krw83CMAxlZWXprbfe0vvvv6/w8HC38aioKHXt2tVtDx45ckQ1NTXsQVhy//3366OPPlJ1dbXZxowZo0cffdT8N3sO19q9997b6k9C/OEPf9CgQYMkSeHh4bLb7W77rr6+Xrt372bfwZKvvvpKvr7u/xfbz89PLS0tkthzNyMe+buBOZ1OpaWlacyYMRo7dqwKCgrU0NCg9PT0zl4abgKZmZnasGGDfvOb36hXr17mc9uBgYHq1q2bAgMDlZGRIafTqVtuuUW9e/fWU089pZiYGN1zzz2dvHp8F/Xq1cv8jt4VPXr0UFBQkNnPnsO1Nnv2bMXGxmrRokX66U9/qj179mjNmjVas2aNJJl/C+3555/X4MGDFR4ervnz52vAgAFyOBydu3h8J/3jP/6jXnjhBd1222266667dODAAS1fvlw/+9nPJLHnbkqd/ZpBtG/VqlXGbbfdZvj7+xtjx441du3a1dlLwk1Ckse2bt06s+Yvf/mL8eSTTxp9+/Y1unfvbvzTP/2TcfLkyc5bNG4633xtumGw53B9bN261Rg2bJgREBBgREREGGvWrHEbb2lpMebPn2+EhIQYAQEBxv33328cOXKkk1aL77r6+npj5syZxm233WbYbDbjhz/8ofEv//IvRmNjo1nDnru5+BjGN/5sMwAAAACgw/gOFQAAAABYRKACAAAAAIsIVAAAAABgEYEKAAAAACwiUAEAAACARQQqAAAAALCIQAUAAAAAFhGoAAAAAMAiAhUAAAAAWESgAgAAAACLCFQAAAAAYNH/A1R6oh+ReO8oAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(10,4))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.bar(np.arange(len(c)), np.array(sorted(c.values(), reverse=True)) / total_freq, width = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('soap', 'cabinet')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[23], nouns[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = [x[0] for x in train_pairs]\n",
    "test_sentences = [x[0] for x in test_pairs]\n",
    "\"a cabinet is at the bottom of a soap.\" in train_sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Draft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../diffuser_colored_sq/\")\n",
    "from model import T2IDiffusion\n",
    "from utils import *\n",
    "from torchsummary import summary\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2DConditionalModel_with_posemb only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n"
     ]
    }
   ],
   "source": [
    "config = ConditionalTrainingConfig()\n",
    "model = T2IDiffusion(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "image = randn_tensor((1, 3, 64, 32), device=device)\n",
    "encoder_hidden_states = randn_tensor((1, 8, 512))\n",
    "timesteps=torch.tensor([5])\n",
    "#summary(model.unet, [image, encoder_hidden_states, 0])\n",
    "# print(summary(\n",
    "#     model.unet,\n",
    "#     #input_data = [(2, 3, 64, 32), (1,), (2, 8, 512)], \n",
    "#     input_data = [image, timesteps, encoder_hidden_states],\n",
    "#     batch_dim = 0, \n",
    "#     dtypes=[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor], \n",
    "#     device=device,\n",
    "#     depth = 10, \n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "|                                  Modules                                   | #Params  |    Param shape     |\n",
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "|                            unet.conv_in.weight                             |   1728   |   [64, 3, 3, 3]    |\n",
      "|                             unet.conv_in.bias                              |    64    |        [64]        |\n",
      "|                    unet.time_embedding.linear_1.weight                     |  16384   |     [256, 64]      |\n",
      "|                     unet.time_embedding.linear_1.bias                      |   256    |       [256]        |\n",
      "|                    unet.time_embedding.linear_2.weight                     |  65536   |     [256, 256]     |\n",
      "|                     unet.time_embedding.linear_2.bias                      |   256    |       [256]        |\n",
      "|                        unet.encoder_hid_proj.weight                        |  65536   |     [128, 512]     |\n",
      "|                         unet.encoder_hid_proj.bias                         |   128    |       [128]        |\n",
      "|                 unet.down_blocks.0.resnets.0.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.0.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.conv1.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.0.conv1.bias                   |    64    |        [64]        |\n",
      "|             unet.down_blocks.0.resnets.0.time_emb_proj.weight              |  16384   |     [64, 256]      |\n",
      "|              unet.down_blocks.0.resnets.0.time_emb_proj.bias               |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.norm2.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.0.norm2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.conv2.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.0.conv2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.1.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.conv1.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.1.conv1.bias                   |    64    |        [64]        |\n",
      "|             unet.down_blocks.0.resnets.1.time_emb_proj.weight              |  16384   |     [64, 256]      |\n",
      "|              unet.down_blocks.0.resnets.1.time_emb_proj.bias               |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.norm2.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.1.norm2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.conv2.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.1.conv2.bias                   |    64    |        [64]        |\n",
      "|               unet.down_blocks.0.downsamplers.0.conv.weight                |  36864   |   [64, 64, 3, 3]   |\n",
      "|                unet.down_blocks.0.downsamplers.0.conv.bias                 |    64    |        [64]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias       |   256    |       [256]        |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight  |  524288  |    [2048, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias   |   2048   |       [2048]       |\n",
      "|    unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight    |  262144  |    [256, 1024]     |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias     |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.0.proj_out.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.down_blocks.1.attentions.0.proj_out.bias                |   1024   |       [1024]       |\n",
      "|           unet.down_blocks.1.attentions.0.pos_embed.proj.weight            |  262144  |  [256, 256, 2, 2]  |\n",
      "|            unet.down_blocks.1.attentions.0.pos_embed.proj.bias             |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.0.norm_out.weight               |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.attentions.0.norm_out.bias                |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias       |   256    |       [256]        |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight  |  524288  |    [2048, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias   |   2048   |       [2048]       |\n",
      "|    unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight    |  262144  |    [256, 1024]     |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias     |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.1.proj_out.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.down_blocks.1.attentions.1.proj_out.bias                |   1024   |       [1024]       |\n",
      "|           unet.down_blocks.1.attentions.1.pos_embed.proj.weight            |  262144  |  [256, 256, 2, 2]  |\n",
      "|            unet.down_blocks.1.attentions.1.pos_embed.proj.bias             |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.1.norm_out.weight               |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.attentions.1.norm_out.bias                |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.1.resnets.0.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.1.resnets.0.conv1.weight                  |  147456  |  [256, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.1.resnets.0.conv1.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.0.time_emb_proj.weight              |  65536   |     [256, 256]     |\n",
      "|              unet.down_blocks.1.resnets.0.time_emb_proj.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.norm2.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.0.norm2.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.conv2.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.0.conv2.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.0.conv_shortcut.weight              |  16384   |  [256, 64, 1, 1]   |\n",
      "|              unet.down_blocks.1.resnets.0.conv_shortcut.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.norm1.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.1.norm1.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.conv1.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.1.conv1.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.1.time_emb_proj.weight              |  65536   |     [256, 256]     |\n",
      "|              unet.down_blocks.1.resnets.1.time_emb_proj.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.norm2.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.1.norm2.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.conv2.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.1.conv2.bias                   |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.downsamplers.0.conv.weight                |  589824  |  [256, 256, 3, 3]  |\n",
      "|                unet.down_blocks.1.downsamplers.0.conv.bias                 |   256    |       [256]        |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias       |   1024   |       [1024]       |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight  | 8388608  |    [8192, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias   |   8192   |       [8192]       |\n",
      "|    unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight    | 4194304  |    [1024, 4096]    |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias     |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.0.proj_out.weight               | 4194304  |    [4096, 1024]    |\n",
      "|               unet.down_blocks.2.attentions.0.proj_out.bias                |   4096   |       [4096]       |\n",
      "|           unet.down_blocks.2.attentions.0.pos_embed.proj.weight            | 4194304  | [1024, 1024, 2, 2] |\n",
      "|            unet.down_blocks.2.attentions.0.pos_embed.proj.bias             |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.0.norm_out.weight               |   1024   |       [1024]       |\n",
      "|               unet.down_blocks.2.attentions.0.norm_out.bias                |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias       |   1024   |       [1024]       |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight  | 8388608  |    [8192, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias   |   8192   |       [8192]       |\n",
      "|    unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight    | 4194304  |    [1024, 4096]    |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias     |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.1.proj_out.weight               | 4194304  |    [4096, 1024]    |\n",
      "|               unet.down_blocks.2.attentions.1.proj_out.bias                |   4096   |       [4096]       |\n",
      "|           unet.down_blocks.2.attentions.1.pos_embed.proj.weight            | 4194304  | [1024, 1024, 2, 2] |\n",
      "|            unet.down_blocks.2.attentions.1.pos_embed.proj.bias             |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.1.norm_out.weight               |   1024   |       [1024]       |\n",
      "|               unet.down_blocks.2.attentions.1.norm_out.bias                |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.norm1.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.2.resnets.0.norm1.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.2.resnets.0.conv1.weight                  | 2359296  | [1024, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.2.resnets.0.conv1.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.0.time_emb_proj.weight              |  262144  |    [1024, 256]     |\n",
      "|              unet.down_blocks.2.resnets.0.time_emb_proj.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.norm2.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.0.norm2.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.conv2.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.0.conv2.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.0.conv_shortcut.weight              |  262144  | [1024, 256, 1, 1]  |\n",
      "|              unet.down_blocks.2.resnets.0.conv_shortcut.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.norm1.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.1.norm1.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.conv1.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.1.conv1.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.1.time_emb_proj.weight              |  262144  |    [1024, 256]     |\n",
      "|              unet.down_blocks.2.resnets.1.time_emb_proj.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.norm2.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.1.norm2.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.conv2.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.1.conv2.bias                   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.0.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.0.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.0.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.0.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.0.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.0.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.1.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.1.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.1.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.1.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.1.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.1.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.2.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.2.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.2.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.2.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.2.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.2.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.norm1.weight                   |   2048   |       [2048]       |\n",
      "|                   unet.up_blocks.0.resnets.0.norm1.bias                    |   2048   |       [2048]       |\n",
      "|                  unet.up_blocks.0.resnets.0.conv1.weight                   | 18874368 | [1024, 2048, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.0.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.0.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.0.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.0.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.0.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.0.conv_shortcut.weight               | 2097152  | [1024, 2048, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.0.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.norm1.weight                   |   2048   |       [2048]       |\n",
      "|                   unet.up_blocks.0.resnets.1.norm1.bias                    |   2048   |       [2048]       |\n",
      "|                  unet.up_blocks.0.resnets.1.conv1.weight                   | 18874368 | [1024, 2048, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.1.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.1.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.1.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.1.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.1.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.1.conv_shortcut.weight               | 2097152  | [1024, 2048, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.1.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.norm1.weight                   |   1280   |       [1280]       |\n",
      "|                   unet.up_blocks.0.resnets.2.norm1.bias                    |   1280   |       [1280]       |\n",
      "|                  unet.up_blocks.0.resnets.2.conv1.weight                   | 11796480 | [1024, 1280, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.2.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.2.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.2.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.2.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.2.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.2.conv_shortcut.weight               | 1310720  | [1024, 1280, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.2.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                 unet.up_blocks.0.upsamplers.0.conv.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.up_blocks.0.upsamplers.0.conv.bias                   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.0.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.0.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.0.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.0.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.0.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.0.norm_out.bias                 |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.1.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.1.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.1.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.1.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.1.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.1.norm_out.bias                 |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.2.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.2.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.2.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.2.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.2.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.2.norm_out.bias                 |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.norm1.weight                   |   1280   |       [1280]       |\n",
      "|                   unet.up_blocks.1.resnets.0.norm1.bias                    |   1280   |       [1280]       |\n",
      "|                  unet.up_blocks.1.resnets.0.conv1.weight                   | 2949120  | [256, 1280, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.0.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.0.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.0.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.0.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.0.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.0.conv_shortcut.weight               |  327680  | [256, 1280, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.0.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.norm1.weight                   |   512    |       [512]        |\n",
      "|                   unet.up_blocks.1.resnets.1.norm1.bias                    |   512    |       [512]        |\n",
      "|                  unet.up_blocks.1.resnets.1.conv1.weight                   | 1179648  |  [256, 512, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.1.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.1.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.1.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.1.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.1.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.1.conv_shortcut.weight               |  131072  |  [256, 512, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.1.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.norm1.weight                   |   320    |       [320]        |\n",
      "|                   unet.up_blocks.1.resnets.2.norm1.bias                    |   320    |       [320]        |\n",
      "|                  unet.up_blocks.1.resnets.2.conv1.weight                   |  737280  |  [256, 320, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.2.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.2.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.2.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.2.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.2.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.2.conv_shortcut.weight               |  81920   |  [256, 320, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.2.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                 unet.up_blocks.1.upsamplers.0.conv.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.up_blocks.1.upsamplers.0.conv.bias                   |   256    |       [256]        |\n",
      "|                  unet.up_blocks.2.resnets.0.norm1.weight                   |   320    |       [320]        |\n",
      "|                   unet.up_blocks.2.resnets.0.norm1.bias                    |   320    |       [320]        |\n",
      "|                  unet.up_blocks.2.resnets.0.conv1.weight                   |  184320  |  [64, 320, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.0.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.0.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.0.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.0.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.0.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.0.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.0.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.0.conv_shortcut.weight               |  20480   |  [64, 320, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.0.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.norm1.weight                   |   128    |       [128]        |\n",
      "|                   unet.up_blocks.2.resnets.1.norm1.bias                    |   128    |       [128]        |\n",
      "|                  unet.up_blocks.2.resnets.1.conv1.weight                   |  73728   |  [64, 128, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.1.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.1.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.1.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.1.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.1.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.1.conv_shortcut.weight               |   8192   |  [64, 128, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.1.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.norm1.weight                   |   128    |       [128]        |\n",
      "|                   unet.up_blocks.2.resnets.2.norm1.bias                    |   128    |       [128]        |\n",
      "|                  unet.up_blocks.2.resnets.2.conv1.weight                   |  73728   |  [64, 128, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.2.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.2.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.2.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.2.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.2.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.2.conv_shortcut.weight               |   8192   |  [64, 128, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.2.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm1.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm1.bias         |   1024   |       [1024]       |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight     | 1048576  |    [1024, 1024]    |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight     |  131072  |    [1024, 128]     |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight     |  131072  |    [1024, 128]     |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight   | 1048576  |    [1024, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias    |   1024   |       [1024]       |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm2.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm2.bias         |   1024   |       [1024]       |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight     | 1048576  |    [1024, 1024]    |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight     |  131072  |    [1024, 128]     |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight     |  131072  |    [1024, 128]     |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight   | 1048576  |    [1024, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias    |   1024   |       [1024]       |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm3.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm3.bias         |   1024   |       [1024]       |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight    | 8388608  |    [8192, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias     |   8192   |       [8192]       |\n",
      "|      unet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight      | 4194304  |    [1024, 4096]    |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias       |   1024   |       [1024]       |\n",
      "|                unet.mid_block.attentions.0.proj_out.weight                 | 4194304  |    [4096, 1024]    |\n",
      "|                 unet.mid_block.attentions.0.proj_out.bias                  |   4096   |       [4096]       |\n",
      "|             unet.mid_block.attentions.0.pos_embed.proj.weight              | 4194304  | [1024, 1024, 2, 2] |\n",
      "|              unet.mid_block.attentions.0.pos_embed.proj.bias               |   1024   |       [1024]       |\n",
      "|                unet.mid_block.attentions.0.norm_out.weight                 |   1024   |       [1024]       |\n",
      "|                 unet.mid_block.attentions.0.norm_out.bias                  |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.norm1.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.0.norm1.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.conv1.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.0.conv1.bias                     |   1024   |       [1024]       |\n",
      "|               unet.mid_block.resnets.0.time_emb_proj.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.mid_block.resnets.0.time_emb_proj.bias                 |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.norm2.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.0.norm2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.conv2.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.0.conv2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.norm1.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.1.norm1.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.conv1.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.1.conv1.bias                     |   1024   |       [1024]       |\n",
      "|               unet.mid_block.resnets.1.time_emb_proj.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.mid_block.resnets.1.time_emb_proj.bias                 |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.norm2.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.1.norm2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.conv2.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.1.conv2.bias                     |   1024   |       [1024]       |\n",
      "|                         unet.conv_norm_out.weight                          |    64    |        [64]        |\n",
      "|                          unet.conv_norm_out.bias                           |    64    |        [64]        |\n",
      "|                            unet.conv_out.weight                            |   1728   |   [3, 64, 3, 3]    |\n",
      "|                             unet.conv_out.bias                             |    3     |        [3]         |\n",
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "Total Params: 337742723\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337742723"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.unet.down_blocks[2].attentions[0].is_input_patches\n",
    "#model.unet.config.attention_head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519062147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67108864*3 + 4194304*2 + 1024*3 + 256*2 + 309343363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unet.down_blocks[2].attentions[0].config.sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
