{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "os.chdir(\"../scripts/diffuser_icons/\")\n",
    "from dataset import *\n",
    "from config import ConditionalTrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 soda\n",
      "90 ('âˆ¦', 'DejaVuSans')\n"
     ]
    }
   ],
   "source": [
    "max_num_objs = 90\n",
    "with open(\"../../data/nouns/all_nouns.txt\", \"r\") as f:\n",
    "    nouns = [x.strip() for x in f.readlines()][:max_num_objs]\n",
    "print(len(nouns), nouns[0])\n",
    "with open(\"../../data/matplotlib/unicode.jsonl\", \"r\", encoding=\"unicode-escape\") as f: \n",
    "    icons = [(json.loads(x)[0], json.loads(x)[2]) for x in f.readlines()][:max_num_objs]\n",
    "print(len(icons), icons[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 90\n"
     ]
    }
   ],
   "source": [
    "canvas_size = (128, 128)\n",
    "icon_size = 128\n",
    "fontsize = 120\n",
    "train_pairs, test_pairs = create_data_single_obj(nouns, icons, canvas_size=canvas_size, icon_size=icon_size, fontsize=fontsize)\n",
    "print(len(train_pairs), len(test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=128x128>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(train_pairs[5][0])\n",
    "train_pairs[84][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('soap', 'cabinet')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[23], nouns[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = [x[0] for x in train_pairs]\n",
    "test_sentences = [x[0] for x in test_pairs]\n",
    "\"a cabinet is at the bottom of a soap.\" in train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.321096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(train_pairs)/1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../diffuser_colored_sq/\")\n",
    "from model import T2IDiffusion\n",
    "from utils import *\n",
    "from torchsummary import summary\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2DConditionalModel_with_posemb only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n"
     ]
    }
   ],
   "source": [
    "config = ConditionalTrainingConfig()\n",
    "model = T2IDiffusion(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "image = randn_tensor((1, 3, 64, 32), device=device)\n",
    "encoder_hidden_states = randn_tensor((1, 8, 512))\n",
    "timesteps=torch.tensor([5])\n",
    "#summary(model.unet, [image, encoder_hidden_states, 0])\n",
    "# print(summary(\n",
    "#     model.unet,\n",
    "#     #input_data = [(2, 3, 64, 32), (1,), (2, 8, 512)], \n",
    "#     input_data = [image, timesteps, encoder_hidden_states],\n",
    "#     batch_dim = 0, \n",
    "#     dtypes=[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor], \n",
    "#     device=device,\n",
    "#     depth = 10, \n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "|                                  Modules                                   | #Params  |    Param shape     |\n",
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "|                            unet.conv_in.weight                             |   1728   |   [64, 3, 3, 3]    |\n",
      "|                             unet.conv_in.bias                              |    64    |        [64]        |\n",
      "|                    unet.time_embedding.linear_1.weight                     |  16384   |     [256, 64]      |\n",
      "|                     unet.time_embedding.linear_1.bias                      |   256    |       [256]        |\n",
      "|                    unet.time_embedding.linear_2.weight                     |  65536   |     [256, 256]     |\n",
      "|                     unet.time_embedding.linear_2.bias                      |   256    |       [256]        |\n",
      "|                        unet.encoder_hid_proj.weight                        |  65536   |     [128, 512]     |\n",
      "|                         unet.encoder_hid_proj.bias                         |   128    |       [128]        |\n",
      "|                 unet.down_blocks.0.resnets.0.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.0.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.conv1.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.0.conv1.bias                   |    64    |        [64]        |\n",
      "|             unet.down_blocks.0.resnets.0.time_emb_proj.weight              |  16384   |     [64, 256]      |\n",
      "|              unet.down_blocks.0.resnets.0.time_emb_proj.bias               |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.norm2.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.0.norm2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.conv2.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.0.conv2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.1.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.conv1.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.1.conv1.bias                   |    64    |        [64]        |\n",
      "|             unet.down_blocks.0.resnets.1.time_emb_proj.weight              |  16384   |     [64, 256]      |\n",
      "|              unet.down_blocks.0.resnets.1.time_emb_proj.bias               |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.norm2.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.1.norm2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.conv2.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.1.conv2.bias                   |    64    |        [64]        |\n",
      "|               unet.down_blocks.0.downsamplers.0.conv.weight                |  36864   |   [64, 64, 3, 3]   |\n",
      "|                unet.down_blocks.0.downsamplers.0.conv.bias                 |    64    |        [64]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias       |   256    |       [256]        |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight  |  524288  |    [2048, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias   |   2048   |       [2048]       |\n",
      "|    unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight    |  262144  |    [256, 1024]     |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias     |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.0.proj_out.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.down_blocks.1.attentions.0.proj_out.bias                |   1024   |       [1024]       |\n",
      "|           unet.down_blocks.1.attentions.0.pos_embed.proj.weight            |  262144  |  [256, 256, 2, 2]  |\n",
      "|            unet.down_blocks.1.attentions.0.pos_embed.proj.bias             |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.0.norm_out.weight               |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.attentions.0.norm_out.bias                |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias       |   256    |       [256]        |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight  |  524288  |    [2048, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias   |   2048   |       [2048]       |\n",
      "|    unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight    |  262144  |    [256, 1024]     |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias     |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.1.proj_out.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.down_blocks.1.attentions.1.proj_out.bias                |   1024   |       [1024]       |\n",
      "|           unet.down_blocks.1.attentions.1.pos_embed.proj.weight            |  262144  |  [256, 256, 2, 2]  |\n",
      "|            unet.down_blocks.1.attentions.1.pos_embed.proj.bias             |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.1.norm_out.weight               |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.attentions.1.norm_out.bias                |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.1.resnets.0.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.1.resnets.0.conv1.weight                  |  147456  |  [256, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.1.resnets.0.conv1.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.0.time_emb_proj.weight              |  65536   |     [256, 256]     |\n",
      "|              unet.down_blocks.1.resnets.0.time_emb_proj.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.norm2.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.0.norm2.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.conv2.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.0.conv2.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.0.conv_shortcut.weight              |  16384   |  [256, 64, 1, 1]   |\n",
      "|              unet.down_blocks.1.resnets.0.conv_shortcut.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.norm1.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.1.norm1.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.conv1.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.1.conv1.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.1.time_emb_proj.weight              |  65536   |     [256, 256]     |\n",
      "|              unet.down_blocks.1.resnets.1.time_emb_proj.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.norm2.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.1.norm2.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.conv2.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.1.conv2.bias                   |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.downsamplers.0.conv.weight                |  589824  |  [256, 256, 3, 3]  |\n",
      "|                unet.down_blocks.1.downsamplers.0.conv.bias                 |   256    |       [256]        |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias       |   1024   |       [1024]       |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight  | 8388608  |    [8192, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias   |   8192   |       [8192]       |\n",
      "|    unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight    | 4194304  |    [1024, 4096]    |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias     |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.0.proj_out.weight               | 4194304  |    [4096, 1024]    |\n",
      "|               unet.down_blocks.2.attentions.0.proj_out.bias                |   4096   |       [4096]       |\n",
      "|           unet.down_blocks.2.attentions.0.pos_embed.proj.weight            | 4194304  | [1024, 1024, 2, 2] |\n",
      "|            unet.down_blocks.2.attentions.0.pos_embed.proj.bias             |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.0.norm_out.weight               |   1024   |       [1024]       |\n",
      "|               unet.down_blocks.2.attentions.0.norm_out.bias                |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias       |   1024   |       [1024]       |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight  | 8388608  |    [8192, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias   |   8192   |       [8192]       |\n",
      "|    unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight    | 4194304  |    [1024, 4096]    |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias     |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.1.proj_out.weight               | 4194304  |    [4096, 1024]    |\n",
      "|               unet.down_blocks.2.attentions.1.proj_out.bias                |   4096   |       [4096]       |\n",
      "|           unet.down_blocks.2.attentions.1.pos_embed.proj.weight            | 4194304  | [1024, 1024, 2, 2] |\n",
      "|            unet.down_blocks.2.attentions.1.pos_embed.proj.bias             |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.1.norm_out.weight               |   1024   |       [1024]       |\n",
      "|               unet.down_blocks.2.attentions.1.norm_out.bias                |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.norm1.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.2.resnets.0.norm1.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.2.resnets.0.conv1.weight                  | 2359296  | [1024, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.2.resnets.0.conv1.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.0.time_emb_proj.weight              |  262144  |    [1024, 256]     |\n",
      "|              unet.down_blocks.2.resnets.0.time_emb_proj.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.norm2.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.0.norm2.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.conv2.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.0.conv2.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.0.conv_shortcut.weight              |  262144  | [1024, 256, 1, 1]  |\n",
      "|              unet.down_blocks.2.resnets.0.conv_shortcut.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.norm1.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.1.norm1.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.conv1.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.1.conv1.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.1.time_emb_proj.weight              |  262144  |    [1024, 256]     |\n",
      "|              unet.down_blocks.2.resnets.1.time_emb_proj.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.norm2.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.1.norm2.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.conv2.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.1.conv2.bias                   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.0.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.0.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.0.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.0.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.0.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.0.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.1.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.1.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.1.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.1.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.1.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.1.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.2.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.2.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.2.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.2.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.2.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.2.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.norm1.weight                   |   2048   |       [2048]       |\n",
      "|                   unet.up_blocks.0.resnets.0.norm1.bias                    |   2048   |       [2048]       |\n",
      "|                  unet.up_blocks.0.resnets.0.conv1.weight                   | 18874368 | [1024, 2048, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.0.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.0.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.0.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.0.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.0.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.0.conv_shortcut.weight               | 2097152  | [1024, 2048, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.0.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.norm1.weight                   |   2048   |       [2048]       |\n",
      "|                   unet.up_blocks.0.resnets.1.norm1.bias                    |   2048   |       [2048]       |\n",
      "|                  unet.up_blocks.0.resnets.1.conv1.weight                   | 18874368 | [1024, 2048, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.1.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.1.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.1.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.1.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.1.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.1.conv_shortcut.weight               | 2097152  | [1024, 2048, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.1.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.norm1.weight                   |   1280   |       [1280]       |\n",
      "|                   unet.up_blocks.0.resnets.2.norm1.bias                    |   1280   |       [1280]       |\n",
      "|                  unet.up_blocks.0.resnets.2.conv1.weight                   | 11796480 | [1024, 1280, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.2.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.2.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.2.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.2.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.2.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.2.conv_shortcut.weight               | 1310720  | [1024, 1280, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.2.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                 unet.up_blocks.0.upsamplers.0.conv.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.up_blocks.0.upsamplers.0.conv.bias                   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.0.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.0.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.0.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.0.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.0.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.0.norm_out.bias                 |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.1.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.1.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.1.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.1.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.1.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.1.norm_out.bias                 |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.2.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.2.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.2.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.2.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.2.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.2.norm_out.bias                 |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.norm1.weight                   |   1280   |       [1280]       |\n",
      "|                   unet.up_blocks.1.resnets.0.norm1.bias                    |   1280   |       [1280]       |\n",
      "|                  unet.up_blocks.1.resnets.0.conv1.weight                   | 2949120  | [256, 1280, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.0.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.0.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.0.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.0.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.0.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.0.conv_shortcut.weight               |  327680  | [256, 1280, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.0.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.norm1.weight                   |   512    |       [512]        |\n",
      "|                   unet.up_blocks.1.resnets.1.norm1.bias                    |   512    |       [512]        |\n",
      "|                  unet.up_blocks.1.resnets.1.conv1.weight                   | 1179648  |  [256, 512, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.1.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.1.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.1.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.1.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.1.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.1.conv_shortcut.weight               |  131072  |  [256, 512, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.1.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.norm1.weight                   |   320    |       [320]        |\n",
      "|                   unet.up_blocks.1.resnets.2.norm1.bias                    |   320    |       [320]        |\n",
      "|                  unet.up_blocks.1.resnets.2.conv1.weight                   |  737280  |  [256, 320, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.2.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.2.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.2.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.2.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.2.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.2.conv_shortcut.weight               |  81920   |  [256, 320, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.2.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                 unet.up_blocks.1.upsamplers.0.conv.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.up_blocks.1.upsamplers.0.conv.bias                   |   256    |       [256]        |\n",
      "|                  unet.up_blocks.2.resnets.0.norm1.weight                   |   320    |       [320]        |\n",
      "|                   unet.up_blocks.2.resnets.0.norm1.bias                    |   320    |       [320]        |\n",
      "|                  unet.up_blocks.2.resnets.0.conv1.weight                   |  184320  |  [64, 320, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.0.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.0.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.0.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.0.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.0.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.0.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.0.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.0.conv_shortcut.weight               |  20480   |  [64, 320, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.0.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.norm1.weight                   |   128    |       [128]        |\n",
      "|                   unet.up_blocks.2.resnets.1.norm1.bias                    |   128    |       [128]        |\n",
      "|                  unet.up_blocks.2.resnets.1.conv1.weight                   |  73728   |  [64, 128, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.1.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.1.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.1.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.1.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.1.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.1.conv_shortcut.weight               |   8192   |  [64, 128, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.1.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.norm1.weight                   |   128    |       [128]        |\n",
      "|                   unet.up_blocks.2.resnets.2.norm1.bias                    |   128    |       [128]        |\n",
      "|                  unet.up_blocks.2.resnets.2.conv1.weight                   |  73728   |  [64, 128, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.2.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.2.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.2.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.2.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.2.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.2.conv_shortcut.weight               |   8192   |  [64, 128, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.2.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm1.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm1.bias         |   1024   |       [1024]       |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight     | 1048576  |    [1024, 1024]    |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight     |  131072  |    [1024, 128]     |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight     |  131072  |    [1024, 128]     |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight   | 1048576  |    [1024, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias    |   1024   |       [1024]       |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm2.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm2.bias         |   1024   |       [1024]       |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight     | 1048576  |    [1024, 1024]    |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight     |  131072  |    [1024, 128]     |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight     |  131072  |    [1024, 128]     |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight   | 1048576  |    [1024, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias    |   1024   |       [1024]       |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm3.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm3.bias         |   1024   |       [1024]       |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight    | 8388608  |    [8192, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias     |   8192   |       [8192]       |\n",
      "|      unet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight      | 4194304  |    [1024, 4096]    |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias       |   1024   |       [1024]       |\n",
      "|                unet.mid_block.attentions.0.proj_out.weight                 | 4194304  |    [4096, 1024]    |\n",
      "|                 unet.mid_block.attentions.0.proj_out.bias                  |   4096   |       [4096]       |\n",
      "|             unet.mid_block.attentions.0.pos_embed.proj.weight              | 4194304  | [1024, 1024, 2, 2] |\n",
      "|              unet.mid_block.attentions.0.pos_embed.proj.bias               |   1024   |       [1024]       |\n",
      "|                unet.mid_block.attentions.0.norm_out.weight                 |   1024   |       [1024]       |\n",
      "|                 unet.mid_block.attentions.0.norm_out.bias                  |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.norm1.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.0.norm1.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.conv1.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.0.conv1.bias                     |   1024   |       [1024]       |\n",
      "|               unet.mid_block.resnets.0.time_emb_proj.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.mid_block.resnets.0.time_emb_proj.bias                 |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.norm2.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.0.norm2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.conv2.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.0.conv2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.norm1.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.1.norm1.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.conv1.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.1.conv1.bias                     |   1024   |       [1024]       |\n",
      "|               unet.mid_block.resnets.1.time_emb_proj.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.mid_block.resnets.1.time_emb_proj.bias                 |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.norm2.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.1.norm2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.conv2.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.1.conv2.bias                     |   1024   |       [1024]       |\n",
      "|                         unet.conv_norm_out.weight                          |    64    |        [64]        |\n",
      "|                          unet.conv_norm_out.bias                           |    64    |        [64]        |\n",
      "|                            unet.conv_out.weight                            |   1728   |   [3, 64, 3, 3]    |\n",
      "|                             unet.conv_out.bias                             |    3     |        [3]         |\n",
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "Total Params: 337742723\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337742723"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.unet.down_blocks[2].attentions[0].is_input_patches\n",
    "#model.unet.config.attention_head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519062147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67108864*3 + 4194304*2 + 1024*3 + 256*2 + 309343363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unet.down_blocks[2].attentions[0].config.sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
