{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os, sys\n",
    "os.chdir(\"../scripts/diffuser_icons/\")\n",
    "from dataset import *\n",
    "from config import ConditionalTrainingConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 soda\n",
      "30 ('âˆ¦', 'DejaVuSans')\n"
     ]
    }
   ],
   "source": [
    "max_num_objs = 30\n",
    "with open(\"../../data/nouns/all_nouns.txt\", \"r\") as f:\n",
    "    nouns = [x.strip() for x in f.readlines()][:max_num_objs]\n",
    "print(len(nouns), nouns[0])\n",
    "with open(\"../../data/matplotlib/unicode.jsonl\", \"r\", encoding=\"unicode-escape\") as f: \n",
    "    icons = [(json.loads(x)[0], json.loads(x)[2]) for x in f.readlines()][:max_num_objs]\n",
    "print(len(icons), icons[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30\n"
     ]
    }
   ],
   "source": [
    "canvas_size = (256, 256)\n",
    "icon_size = 256\n",
    "fontsize = 220\n",
    "train_pairs, test_pairs = create_data_single_obj(nouns, icons, canvas_size=canvas_size, icon_size=icon_size, fontsize=fontsize)\n",
    "print(len(train_pairs), len(test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=256x256>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(train_pairs[5][0])\n",
    "train_pairs[16][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('soap', 'cabinet')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nouns[23], nouns[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sentences = [x[0] for x in train_pairs]\n",
    "test_sentences = [x[0] for x in test_pairs]\n",
    "\"a cabinet is at the bottom of a soap.\" in train_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.321096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.getsizeof(train_pairs)/1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../diffuser_colored_sq/\")\n",
    "from model import T2IDiffusion\n",
    "from utils import *\n",
    "from torchsummary import summary\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet2DConditionalModel_with_posemb only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n",
      "Transformer2DModel_with_nonsquare_input only_cross_attention=True\n"
     ]
    }
   ],
   "source": [
    "config = ConditionalTrainingConfig()\n",
    "model = T2IDiffusion(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\"\n",
    "image = randn_tensor((1, 3, 64, 32), device=device)\n",
    "encoder_hidden_states = randn_tensor((1, 8, 512))\n",
    "timesteps=torch.tensor([5])\n",
    "#summary(model.unet, [image, encoder_hidden_states, 0])\n",
    "# print(summary(\n",
    "#     model.unet,\n",
    "#     #input_data = [(2, 3, 64, 32), (1,), (2, 8, 512)], \n",
    "#     input_data = [image, timesteps, encoder_hidden_states],\n",
    "#     batch_dim = 0, \n",
    "#     dtypes=[torch.FloatTensor, torch.FloatTensor, torch.FloatTensor], \n",
    "#     device=device,\n",
    "#     depth = 10, \n",
    "# ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "|                                  Modules                                   | #Params  |    Param shape     |\n",
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "|                            unet.conv_in.weight                             |   1728   |   [64, 3, 3, 3]    |\n",
      "|                             unet.conv_in.bias                              |    64    |        [64]        |\n",
      "|                    unet.time_embedding.linear_1.weight                     |  16384   |     [256, 64]      |\n",
      "|                     unet.time_embedding.linear_1.bias                      |   256    |       [256]        |\n",
      "|                    unet.time_embedding.linear_2.weight                     |  65536   |     [256, 256]     |\n",
      "|                     unet.time_embedding.linear_2.bias                      |   256    |       [256]        |\n",
      "|                        unet.encoder_hid_proj.weight                        |  65536   |     [128, 512]     |\n",
      "|                         unet.encoder_hid_proj.bias                         |   128    |       [128]        |\n",
      "|                 unet.down_blocks.0.resnets.0.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.0.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.conv1.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.0.conv1.bias                   |    64    |        [64]        |\n",
      "|             unet.down_blocks.0.resnets.0.time_emb_proj.weight              |  16384   |     [64, 256]      |\n",
      "|              unet.down_blocks.0.resnets.0.time_emb_proj.bias               |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.norm2.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.0.norm2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.0.conv2.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.0.conv2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.1.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.conv1.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.1.conv1.bias                   |    64    |        [64]        |\n",
      "|             unet.down_blocks.0.resnets.1.time_emb_proj.weight              |  16384   |     [64, 256]      |\n",
      "|              unet.down_blocks.0.resnets.1.time_emb_proj.bias               |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.norm2.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.0.resnets.1.norm2.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.0.resnets.1.conv2.weight                  |  36864   |   [64, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.0.resnets.1.conv2.bias                   |    64    |        [64]        |\n",
      "|               unet.down_blocks.0.downsamplers.0.conv.weight                |  36864   |   [64, 64, 3, 3]   |\n",
      "|                unet.down_blocks.0.downsamplers.0.conv.bias                 |    64    |        [64]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm1.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm2.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.0.transformer_blocks.0.norm3.bias       |   256    |       [256]        |\n",
      "| unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight  |  524288  |    [2048, 256]     |\n",
      "|  unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias   |   2048   |       [2048]       |\n",
      "|    unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight    |  262144  |    [256, 1024]     |\n",
      "|     unet.down_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias     |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.0.proj_out.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.down_blocks.1.attentions.0.proj_out.bias                |   1024   |       [1024]       |\n",
      "|           unet.down_blocks.1.attentions.0.pos_embed.proj.weight            |  262144  |  [256, 256, 2, 2]  |\n",
      "|            unet.down_blocks.1.attentions.0.pos_embed.proj.bias             |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.0.norm_out.weight               |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.attentions.0.norm_out.bias                |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm1.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm2.bias       |   256    |       [256]        |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight   |  65536   |     [256, 256]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight   |  32768   |     [256, 128]     |\n",
      "|   unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight   |  32768   |     [256, 128]     |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight |  65536   |     [256, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias  |   256    |       [256]        |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.weight      |   256    |       [256]        |\n",
      "|      unet.down_blocks.1.attentions.1.transformer_blocks.0.norm3.bias       |   256    |       [256]        |\n",
      "| unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight  |  524288  |    [2048, 256]     |\n",
      "|  unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias   |   2048   |       [2048]       |\n",
      "|    unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight    |  262144  |    [256, 1024]     |\n",
      "|     unet.down_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias     |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.1.proj_out.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.down_blocks.1.attentions.1.proj_out.bias                |   1024   |       [1024]       |\n",
      "|           unet.down_blocks.1.attentions.1.pos_embed.proj.weight            |  262144  |  [256, 256, 2, 2]  |\n",
      "|            unet.down_blocks.1.attentions.1.pos_embed.proj.bias             |   256    |       [256]        |\n",
      "|              unet.down_blocks.1.attentions.1.norm_out.weight               |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.attentions.1.norm_out.bias                |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.norm1.weight                  |    64    |        [64]        |\n",
      "|                  unet.down_blocks.1.resnets.0.norm1.bias                   |    64    |        [64]        |\n",
      "|                 unet.down_blocks.1.resnets.0.conv1.weight                  |  147456  |  [256, 64, 3, 3]   |\n",
      "|                  unet.down_blocks.1.resnets.0.conv1.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.0.time_emb_proj.weight              |  65536   |     [256, 256]     |\n",
      "|              unet.down_blocks.1.resnets.0.time_emb_proj.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.norm2.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.0.norm2.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.0.conv2.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.0.conv2.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.0.conv_shortcut.weight              |  16384   |  [256, 64, 1, 1]   |\n",
      "|              unet.down_blocks.1.resnets.0.conv_shortcut.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.norm1.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.1.norm1.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.conv1.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.1.conv1.bias                   |   256    |       [256]        |\n",
      "|             unet.down_blocks.1.resnets.1.time_emb_proj.weight              |  65536   |     [256, 256]     |\n",
      "|              unet.down_blocks.1.resnets.1.time_emb_proj.bias               |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.norm2.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.1.resnets.1.norm2.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.1.resnets.1.conv2.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.1.resnets.1.conv2.bias                   |   256    |       [256]        |\n",
      "|               unet.down_blocks.1.downsamplers.0.conv.weight                |  589824  |  [256, 256, 3, 3]  |\n",
      "|                unet.down_blocks.1.downsamplers.0.conv.bias                 |   256    |       [256]        |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm1.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.attn1.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm2.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.attn2.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.0.transformer_blocks.0.norm3.bias       |   1024   |       [1024]       |\n",
      "| unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.weight  | 8388608  |    [8192, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.0.proj.bias   |   8192   |       [8192]       |\n",
      "|    unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.weight    | 4194304  |    [1024, 4096]    |\n",
      "|     unet.down_blocks.2.attentions.0.transformer_blocks.0.ff.net.2.bias     |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.0.proj_out.weight               | 4194304  |    [4096, 1024]    |\n",
      "|               unet.down_blocks.2.attentions.0.proj_out.bias                |   4096   |       [4096]       |\n",
      "|           unet.down_blocks.2.attentions.0.pos_embed.proj.weight            | 4194304  | [1024, 1024, 2, 2] |\n",
      "|            unet.down_blocks.2.attentions.0.pos_embed.proj.bias             |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.0.norm_out.weight               |   1024   |       [1024]       |\n",
      "|               unet.down_blocks.2.attentions.0.norm_out.bias                |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm1.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.attn1.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm2.bias       |   1024   |       [1024]       |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_q.weight   | 1048576  |    [1024, 1024]    |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_k.weight   |  131072  |    [1024, 128]     |\n",
      "|   unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_v.weight   |  131072  |    [1024, 128]     |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.weight | 1048576  |    [1024, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.attn2.to_out.0.bias  |   1024   |       [1024]       |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.weight      |   1024   |       [1024]       |\n",
      "|      unet.down_blocks.2.attentions.1.transformer_blocks.0.norm3.bias       |   1024   |       [1024]       |\n",
      "| unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.weight  | 8388608  |    [8192, 1024]    |\n",
      "|  unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.0.proj.bias   |   8192   |       [8192]       |\n",
      "|    unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.weight    | 4194304  |    [1024, 4096]    |\n",
      "|     unet.down_blocks.2.attentions.1.transformer_blocks.0.ff.net.2.bias     |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.1.proj_out.weight               | 4194304  |    [4096, 1024]    |\n",
      "|               unet.down_blocks.2.attentions.1.proj_out.bias                |   4096   |       [4096]       |\n",
      "|           unet.down_blocks.2.attentions.1.pos_embed.proj.weight            | 4194304  | [1024, 1024, 2, 2] |\n",
      "|            unet.down_blocks.2.attentions.1.pos_embed.proj.bias             |   1024   |       [1024]       |\n",
      "|              unet.down_blocks.2.attentions.1.norm_out.weight               |   1024   |       [1024]       |\n",
      "|               unet.down_blocks.2.attentions.1.norm_out.bias                |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.norm1.weight                  |   256    |       [256]        |\n",
      "|                  unet.down_blocks.2.resnets.0.norm1.bias                   |   256    |       [256]        |\n",
      "|                 unet.down_blocks.2.resnets.0.conv1.weight                  | 2359296  | [1024, 256, 3, 3]  |\n",
      "|                  unet.down_blocks.2.resnets.0.conv1.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.0.time_emb_proj.weight              |  262144  |    [1024, 256]     |\n",
      "|              unet.down_blocks.2.resnets.0.time_emb_proj.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.norm2.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.0.norm2.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.0.conv2.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.0.conv2.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.0.conv_shortcut.weight              |  262144  | [1024, 256, 1, 1]  |\n",
      "|              unet.down_blocks.2.resnets.0.conv_shortcut.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.norm1.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.1.norm1.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.conv1.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.1.conv1.bias                   |   1024   |       [1024]       |\n",
      "|             unet.down_blocks.2.resnets.1.time_emb_proj.weight              |  262144  |    [1024, 256]     |\n",
      "|              unet.down_blocks.2.resnets.1.time_emb_proj.bias               |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.norm2.weight                  |   1024   |       [1024]       |\n",
      "|                  unet.down_blocks.2.resnets.1.norm2.bias                   |   1024   |       [1024]       |\n",
      "|                 unet.down_blocks.2.resnets.1.conv2.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.down_blocks.2.resnets.1.conv2.bias                   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.0.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.0.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.0.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.0.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.0.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.0.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.0.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.0.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.1.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.1.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.1.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.1.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.1.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.1.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.1.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.1.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm1.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm1.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.attn1.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm2.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm2.bias        |   1024   |       [1024]       |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_q.weight    | 1048576  |    [1024, 1024]    |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_k.weight    |  131072  |    [1024, 128]     |\n",
      "|    unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_v.weight    |  131072  |    [1024, 128]     |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.weight  | 1048576  |    [1024, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.attn2.to_out.0.bias   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.norm3.weight       |   1024   |       [1024]       |\n",
      "|       unet.up_blocks.0.attentions.2.transformer_blocks.0.norm3.bias        |   1024   |       [1024]       |\n",
      "|  unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.weight   | 8388608  |    [8192, 1024]    |\n",
      "|   unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.0.proj.bias    |   8192   |       [8192]       |\n",
      "|     unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.weight     | 4194304  |    [1024, 4096]    |\n",
      "|      unet.up_blocks.0.attentions.2.transformer_blocks.0.ff.net.2.bias      |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.2.proj_out.weight                | 4194304  |    [4096, 1024]    |\n",
      "|                unet.up_blocks.0.attentions.2.proj_out.bias                 |   4096   |       [4096]       |\n",
      "|            unet.up_blocks.0.attentions.2.pos_embed.proj.weight             | 4194304  | [1024, 1024, 2, 2] |\n",
      "|             unet.up_blocks.0.attentions.2.pos_embed.proj.bias              |   1024   |       [1024]       |\n",
      "|               unet.up_blocks.0.attentions.2.norm_out.weight                |   1024   |       [1024]       |\n",
      "|                unet.up_blocks.0.attentions.2.norm_out.bias                 |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.norm1.weight                   |   2048   |       [2048]       |\n",
      "|                   unet.up_blocks.0.resnets.0.norm1.bias                    |   2048   |       [2048]       |\n",
      "|                  unet.up_blocks.0.resnets.0.conv1.weight                   | 18874368 | [1024, 2048, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.0.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.0.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.0.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.0.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.0.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.0.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.0.conv_shortcut.weight               | 2097152  | [1024, 2048, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.0.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.norm1.weight                   |   2048   |       [2048]       |\n",
      "|                   unet.up_blocks.0.resnets.1.norm1.bias                    |   2048   |       [2048]       |\n",
      "|                  unet.up_blocks.0.resnets.1.conv1.weight                   | 18874368 | [1024, 2048, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.1.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.1.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.1.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.1.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.1.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.1.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.1.conv_shortcut.weight               | 2097152  | [1024, 2048, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.1.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.norm1.weight                   |   1280   |       [1280]       |\n",
      "|                   unet.up_blocks.0.resnets.2.norm1.bias                    |   1280   |       [1280]       |\n",
      "|                  unet.up_blocks.0.resnets.2.conv1.weight                   | 11796480 | [1024, 1280, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.2.conv1.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.2.time_emb_proj.weight               |  262144  |    [1024, 256]     |\n",
      "|               unet.up_blocks.0.resnets.2.time_emb_proj.bias                |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.norm2.weight                   |   1024   |       [1024]       |\n",
      "|                   unet.up_blocks.0.resnets.2.norm2.bias                    |   1024   |       [1024]       |\n",
      "|                  unet.up_blocks.0.resnets.2.conv2.weight                   | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                   unet.up_blocks.0.resnets.2.conv2.bias                    |   1024   |       [1024]       |\n",
      "|              unet.up_blocks.0.resnets.2.conv_shortcut.weight               | 1310720  | [1024, 1280, 1, 1] |\n",
      "|               unet.up_blocks.0.resnets.2.conv_shortcut.bias                |   1024   |       [1024]       |\n",
      "|                 unet.up_blocks.0.upsamplers.0.conv.weight                  | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                  unet.up_blocks.0.upsamplers.0.conv.bias                   |   1024   |       [1024]       |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.0.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.0.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.0.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.0.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.0.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.0.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.0.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.0.norm_out.bias                 |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.1.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.1.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.1.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.1.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.1.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.1.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.1.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.1.norm_out.bias                 |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm1.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm1.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.attn1.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm2.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm2.bias        |   256    |       [256]        |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_q.weight    |  65536   |     [256, 256]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_k.weight    |  32768   |     [256, 128]     |\n",
      "|    unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_v.weight    |  32768   |     [256, 128]     |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.weight  |  65536   |     [256, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.attn2.to_out.0.bias   |   256    |       [256]        |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.norm3.weight       |   256    |       [256]        |\n",
      "|       unet.up_blocks.1.attentions.2.transformer_blocks.0.norm3.bias        |   256    |       [256]        |\n",
      "|  unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.weight   |  524288  |    [2048, 256]     |\n",
      "|   unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.0.proj.bias    |   2048   |       [2048]       |\n",
      "|     unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.weight     |  262144  |    [256, 1024]     |\n",
      "|      unet.up_blocks.1.attentions.2.transformer_blocks.0.ff.net.2.bias      |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.2.proj_out.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.up_blocks.1.attentions.2.proj_out.bias                 |   1024   |       [1024]       |\n",
      "|            unet.up_blocks.1.attentions.2.pos_embed.proj.weight             |  262144  |  [256, 256, 2, 2]  |\n",
      "|             unet.up_blocks.1.attentions.2.pos_embed.proj.bias              |   256    |       [256]        |\n",
      "|               unet.up_blocks.1.attentions.2.norm_out.weight                |   256    |       [256]        |\n",
      "|                unet.up_blocks.1.attentions.2.norm_out.bias                 |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.norm1.weight                   |   1280   |       [1280]       |\n",
      "|                   unet.up_blocks.1.resnets.0.norm1.bias                    |   1280   |       [1280]       |\n",
      "|                  unet.up_blocks.1.resnets.0.conv1.weight                   | 2949120  | [256, 1280, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.0.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.0.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.0.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.0.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.0.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.0.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.0.conv_shortcut.weight               |  327680  | [256, 1280, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.0.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.norm1.weight                   |   512    |       [512]        |\n",
      "|                   unet.up_blocks.1.resnets.1.norm1.bias                    |   512    |       [512]        |\n",
      "|                  unet.up_blocks.1.resnets.1.conv1.weight                   | 1179648  |  [256, 512, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.1.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.1.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.1.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.1.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.1.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.1.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.1.conv_shortcut.weight               |  131072  |  [256, 512, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.1.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.norm1.weight                   |   320    |       [320]        |\n",
      "|                   unet.up_blocks.1.resnets.2.norm1.bias                    |   320    |       [320]        |\n",
      "|                  unet.up_blocks.1.resnets.2.conv1.weight                   |  737280  |  [256, 320, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.2.conv1.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.2.time_emb_proj.weight               |  65536   |     [256, 256]     |\n",
      "|               unet.up_blocks.1.resnets.2.time_emb_proj.bias                |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.norm2.weight                   |   256    |       [256]        |\n",
      "|                   unet.up_blocks.1.resnets.2.norm2.bias                    |   256    |       [256]        |\n",
      "|                  unet.up_blocks.1.resnets.2.conv2.weight                   |  589824  |  [256, 256, 3, 3]  |\n",
      "|                   unet.up_blocks.1.resnets.2.conv2.bias                    |   256    |       [256]        |\n",
      "|              unet.up_blocks.1.resnets.2.conv_shortcut.weight               |  81920   |  [256, 320, 1, 1]  |\n",
      "|               unet.up_blocks.1.resnets.2.conv_shortcut.bias                |   256    |       [256]        |\n",
      "|                 unet.up_blocks.1.upsamplers.0.conv.weight                  |  589824  |  [256, 256, 3, 3]  |\n",
      "|                  unet.up_blocks.1.upsamplers.0.conv.bias                   |   256    |       [256]        |\n",
      "|                  unet.up_blocks.2.resnets.0.norm1.weight                   |   320    |       [320]        |\n",
      "|                   unet.up_blocks.2.resnets.0.norm1.bias                    |   320    |       [320]        |\n",
      "|                  unet.up_blocks.2.resnets.0.conv1.weight                   |  184320  |  [64, 320, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.0.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.0.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.0.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.0.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.0.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.0.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.0.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.0.conv_shortcut.weight               |  20480   |  [64, 320, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.0.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.norm1.weight                   |   128    |       [128]        |\n",
      "|                   unet.up_blocks.2.resnets.1.norm1.bias                    |   128    |       [128]        |\n",
      "|                  unet.up_blocks.2.resnets.1.conv1.weight                   |  73728   |  [64, 128, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.1.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.1.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.1.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.1.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.1.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.1.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.1.conv_shortcut.weight               |   8192   |  [64, 128, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.1.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.norm1.weight                   |   128    |       [128]        |\n",
      "|                   unet.up_blocks.2.resnets.2.norm1.bias                    |   128    |       [128]        |\n",
      "|                  unet.up_blocks.2.resnets.2.conv1.weight                   |  73728   |  [64, 128, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.2.conv1.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.2.time_emb_proj.weight               |  16384   |     [64, 256]      |\n",
      "|               unet.up_blocks.2.resnets.2.time_emb_proj.bias                |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.norm2.weight                   |    64    |        [64]        |\n",
      "|                   unet.up_blocks.2.resnets.2.norm2.bias                    |    64    |        [64]        |\n",
      "|                  unet.up_blocks.2.resnets.2.conv2.weight                   |  36864   |   [64, 64, 3, 3]   |\n",
      "|                   unet.up_blocks.2.resnets.2.conv2.bias                    |    64    |        [64]        |\n",
      "|              unet.up_blocks.2.resnets.2.conv_shortcut.weight               |   8192   |  [64, 128, 1, 1]   |\n",
      "|               unet.up_blocks.2.resnets.2.conv_shortcut.bias                |    64    |        [64]        |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm1.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm1.bias         |   1024   |       [1024]       |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_q.weight     | 1048576  |    [1024, 1024]    |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_k.weight     |  131072  |    [1024, 128]     |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_v.weight     |  131072  |    [1024, 128]     |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.weight   | 1048576  |    [1024, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.attn1.to_out.0.bias    |   1024   |       [1024]       |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm2.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm2.bias         |   1024   |       [1024]       |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_q.weight     | 1048576  |    [1024, 1024]    |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_k.weight     |  131072  |    [1024, 128]     |\n",
      "|     unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_v.weight     |  131072  |    [1024, 128]     |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.weight   | 1048576  |    [1024, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.attn2.to_out.0.bias    |   1024   |       [1024]       |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.norm3.weight        |   1024   |       [1024]       |\n",
      "|        unet.mid_block.attentions.0.transformer_blocks.0.norm3.bias         |   1024   |       [1024]       |\n",
      "|   unet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.weight    | 8388608  |    [8192, 1024]    |\n",
      "|    unet.mid_block.attentions.0.transformer_blocks.0.ff.net.0.proj.bias     |   8192   |       [8192]       |\n",
      "|      unet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.weight      | 4194304  |    [1024, 4096]    |\n",
      "|       unet.mid_block.attentions.0.transformer_blocks.0.ff.net.2.bias       |   1024   |       [1024]       |\n",
      "|                unet.mid_block.attentions.0.proj_out.weight                 | 4194304  |    [4096, 1024]    |\n",
      "|                 unet.mid_block.attentions.0.proj_out.bias                  |   4096   |       [4096]       |\n",
      "|             unet.mid_block.attentions.0.pos_embed.proj.weight              | 4194304  | [1024, 1024, 2, 2] |\n",
      "|              unet.mid_block.attentions.0.pos_embed.proj.bias               |   1024   |       [1024]       |\n",
      "|                unet.mid_block.attentions.0.norm_out.weight                 |   1024   |       [1024]       |\n",
      "|                 unet.mid_block.attentions.0.norm_out.bias                  |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.norm1.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.0.norm1.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.conv1.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.0.conv1.bias                     |   1024   |       [1024]       |\n",
      "|               unet.mid_block.resnets.0.time_emb_proj.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.mid_block.resnets.0.time_emb_proj.bias                 |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.norm2.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.0.norm2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.0.conv2.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.0.conv2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.norm1.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.1.norm1.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.conv1.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.1.conv1.bias                     |   1024   |       [1024]       |\n",
      "|               unet.mid_block.resnets.1.time_emb_proj.weight                |  262144  |    [1024, 256]     |\n",
      "|                unet.mid_block.resnets.1.time_emb_proj.bias                 |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.norm2.weight                    |   1024   |       [1024]       |\n",
      "|                    unet.mid_block.resnets.1.norm2.bias                     |   1024   |       [1024]       |\n",
      "|                   unet.mid_block.resnets.1.conv2.weight                    | 9437184  | [1024, 1024, 3, 3] |\n",
      "|                    unet.mid_block.resnets.1.conv2.bias                     |   1024   |       [1024]       |\n",
      "|                         unet.conv_norm_out.weight                          |    64    |        [64]        |\n",
      "|                          unet.conv_norm_out.bias                           |    64    |        [64]        |\n",
      "|                            unet.conv_out.weight                            |   1728   |   [3, 64, 3, 3]    |\n",
      "|                             unet.conv_out.bias                             |    3     |        [3]         |\n",
      "+----------------------------------------------------------------------------+----------+--------------------+\n",
      "Total Params: 337742723\n"
     ]
    }
   ],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337742723"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.unet.down_blocks[2].attentions[0].is_input_patches\n",
    "#model.unet.config.attention_head_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "519062147"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "67108864*3 + 4194304*2 + 1024*3 + 256*2 + 309343363"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.unet.down_blocks[2].attentions[0].config.sample_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
