{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import os, json, re, random, io, pytz, itertools, shutil\n",
    "from matplotlib.patches import Circle, Wedge, Polygon, Rectangle\n",
    "from pprint import pprint\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SIZES = [8, 9, 10]\n",
    "OFFSETS = [-1, 0, 1]\n",
    "COLORS = {\n",
    "    \"red\": \"#ff0000\", \n",
    "    \"blue\": \"#0000ff\", \n",
    "    \"green\": \"#008000\",\n",
    "    \"black\": \"#000000\",\n",
    "    \"pink\": \"#ff69b4\", \n",
    "    \"yellow\": \"#ffff00\",\n",
    "    \"purple\": \"#800080\",\n",
    "    \"orange\": \"#FFA500\",\n",
    "    \"cyan\": \"#00FFFF\",\n",
    "    #\"brown\": \"#A52A2A\",\n",
    "    \"khaki\": \"#BDB76B\",\n",
    "    \"grey\": \"#808080\",\n",
    "    \"lime\":\"#00FF00\",\n",
    "}\n",
    "RELATIONS = [\"{0} is on top of {1}.\", \"{1} is at the bottom of {0}.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"../data/matplotlib/colored_2sq\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:00<00:00, 115.50it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 102.23it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 113.92it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.45it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 115.59it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 101.13it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 116.56it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.20it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 115.29it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.25it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 116.18it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.84it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 116.07it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.56it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 114.73it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.32it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 116.56it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.55it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 116.34it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.28it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 116.13it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.35it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.34it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.54it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 116.27it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.45it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 116.09it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 115.15it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.07it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 115.73it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.61it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.36it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 100.08it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 115.33it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.76it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.52it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.41it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.50it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.56it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.36it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.48it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 113.87it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.20it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.18it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.24it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.08it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.97it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.60it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.87it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.64it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.08it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.09it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.21it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.55it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 99.10it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.69it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.86it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.34it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.69it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.56it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 96.56it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.96it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.46it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 111.71it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.15it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.62it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.13it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.06it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 114.61it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.36it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.30it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.32it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.63it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.85it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.61it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.43it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.29it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.03it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.32it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.48it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.17it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.03it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.51it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.77it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.58it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.78it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.74it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.82it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.90it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 115.00it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.90it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.87it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.17it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.73it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 98.16it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.75it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.75it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.47it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.44it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.10it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.30it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.74it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.42it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.12it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.65it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 112.41it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.33it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.46it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 96.89it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.84it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 115.48it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.37it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.39it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.38it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.21it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.28it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.57it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.29it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.96it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 97.07it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.46it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 96.76it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 113.96it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 96.19it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.05it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 96.48it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.50it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 96.27it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 115.32it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 114.58it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 96.89it/s] \n",
      "100%|██████████| 81/81 [00:00<00:00, 114.90it/s]\n"
     ]
    }
   ],
   "source": [
    "im_count = 0\n",
    "layout_count = 0\n",
    "pairs = []\n",
    "annotations = {\n",
    "      \"metadata\": {\n",
    "            \"relations\": RELATIONS,\n",
    "            \"colors\": COLORS,\n",
    "            \"sizes\": SIZES,\n",
    "            \"offsets\": OFFSETS,\n",
    "      }\n",
    "}\n",
    "os.system(f\"rm -rf {dir}/images/*\")\n",
    "for c1, c2 in itertools.product(COLORS, COLORS):\n",
    "      if c1 == c2: continue\n",
    "      for r1, r2, o1, o2 in tqdm(itertools.product(SIZES, SIZES, OFFSETS, OFFSETS), total=len(SIZES)**2*len(OFFSETS)**2):\n",
    "            plt.ioff() # disable plt.show()\n",
    "            fig = plt.figure(dpi=8, figsize=(4,4)) # The resulting resolution will be 128x128\n",
    "            W, H = fig.get_size_inches()*fig.dpi\n",
    "            fig.patches.append(Rectangle((0.5 - (r1+o1)/2.0/W, 0.5), r1/W, r1/H, facecolor=COLORS[c1], transform=fig.transFigure)) \n",
    "            fig.patches.append(Rectangle((0.5 - (r2+o2)/2.0/W, 0.5 - r2/H), r2/W, r2/H, facecolor=COLORS[c2], transform=fig.transFigure))\n",
    "            plt.axis('off')\n",
    "            imgid = str(im_count+10000000)[1:]\n",
    "            fig.savefig(f\"{dir}/images/{imgid}.png\", format='png')\n",
    "            plt.close(fig)\n",
    "\n",
    "            sentences = []\n",
    "            for i, r in enumerate(RELATIONS):\n",
    "                  sentences.append({\n",
    "                        \"imgid\": imgid,\n",
    "                        \"raw\": r.format(f\"a {c1} square\", f\"a {c2} square\"),\n",
    "                        \"sentid\": f\"{imgid}{i}\"\n",
    "                  })\n",
    "            pairs.append({\n",
    "                  \"imgid\": imgid,\n",
    "                  \"filename\": f\"{imgid}.png\",\n",
    "                  \"layout\": RELATIONS[0].format(c1, c2),\n",
    "                  \"layoutid\": str(layout_count+1000)[1:],\n",
    "                  \"sentences\": sentences,\n",
    "            })\n",
    "            im_count += 1\n",
    "      layout_count += 1\n",
    "      #break\n",
    "annotations['data'] = pairs\n",
    "json.dump(annotations, open(f\"{dir}/annotations.json\", \"w\"), indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABoAAAAaCAYAAACpSkzOAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAAE7AAABOwEf329xAAAAUklEQVR4nGP8////fwY6ACZ6WDJqEUWAhShVWVvxy0/zJmjE8Au6UYtGLYIDRmIKVUYGRrzy/xkIl8vDL+hGLRq1CA6Iqo+IySeEwPALuuFnEQCW6A4tECzQ6wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 32x32 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Trial: figure rendering\n",
    "fig = plt.figure(dpi=8, figsize=(4,4)) # The resulting resolution will be 128x128\n",
    "W, H = fig.get_size_inches()*fig.dpi\n",
    "r1, r2 = 8, 8\n",
    "o1, o2 = 0, 0\n",
    "fig.patches.append(Rectangle((0.5 - (r1+o1)/2.0/W, 0.5 - r1/H), r1/W, r1/H, facecolor=COLORS[\"lime\"], transform=fig.transFigure))\n",
    "fig.patches.append(Rectangle((0.5 - (r2+o2)/2.0/W, 0.5), r2/W, r2/H, facecolor=COLORS[\"pink\"], transform=fig.transFigure)) \n",
    "plt.axis('off')\n",
    "imgid = str(im_count+10000000)[1:]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3+qV/q+maV5f9o6jaWfmZ8v7ROse/GM43EZxkfnV2vGvj1/zL/wD28/8AtKtaFNVKig+pvhqSq1VB9T1Wx13R9UnaDT9VsbuVV3mO3uEkYLkDOATxkj860K8B+B3/ACOt5/2Dn/8ARkde/VWIpKlPlQ8VQVGpyJ3CvmD9o7/koen/APYKj/8ARstfT9cv4k+HfhXxdqMd/rmlfa7qOIQq/wBoljwgJIGEYDqx/OsDnPCP2cf+Sh6h/wBgqT/0bFX0/XL+G/h34V8I6jJf6HpX2S6kiMLP9olkyhIJGHYjqo/KuooA/9k=",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAZElEQVR4Ae2VwQ4AEAxDVfy3+PKZOGtPDkvqqFXZ2wQiov1c/Wf4yfYFknB9REPWmIaF9bLNmC/p7tdH5Ap4h1M1IokI8j8AQFLkcfeA0LuSERmRJCAN+iXLCG7wmHI+qdZHtAHkXA83p7BKLQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=32x32>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at generated images\n",
    "filename = random.choice(os.listdir(f\"{dir}/images\"))\n",
    "im = Image.open(f\"{dir}/images/{filename}\").convert(\"RGB\")\n",
    "im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0000000.png',\n",
      " 'imgid': '0000000',\n",
      " 'layout': 'red is on top of blue.',\n",
      " 'layoutid': '000',\n",
      " 'sentences': [{'imgid': '0000000',\n",
      "                'raw': 'a red square is on top of a blue square.',\n",
      "                'sentid': '00000000'},\n",
      "               {'imgid': '0000000',\n",
      "                'raw': 'a blue square is at the bottom of a red square.',\n",
      "                'sentid': '00000001'}]}\n",
      "10692 10692\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "# Criterion: for the same layout, one description is put in training and the other is put in testing\n",
    "train = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "train.set_index(\"sentid\")\n",
    "test = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "test.set_index(\"sentid\")\n",
    "pairs = json.load(open(f\"{dir}/annotations.json\", \"r\"))[\"data\"]\n",
    "print(len(pairs))\n",
    "pprint(pairs[0])\n",
    "\n",
    "for d in pairs:\n",
    "    train_sentence = int(d['layoutid']) % 2\n",
    "    row = {\n",
    "        \"sentid\": [d['sentences'][train_sentence]['sentid']],\n",
    "        \"filename\": [d['filename']],\n",
    "        \"sentence\": [d['sentences'][train_sentence]['raw']]\n",
    "    }\n",
    "    row = pd.DataFrame(row)\n",
    "    train = pd.concat([train, pd.DataFrame(row)])\n",
    "    test_sentence = 1 - train_sentence\n",
    "    row = {\n",
    "        \"sentid\": [d['sentences'][test_sentence]['sentid']],\n",
    "        \"filename\": [d['filename']],\n",
    "        \"sentence\": [d['sentences'][test_sentence]['raw']]\n",
    "    }\n",
    "    test = pd.concat([test, pd.DataFrame(row)])\n",
    "print(len(train), len(test))\n",
    "\n",
    "train.to_csv(f\"{dir}/split1/train.csv\", index=False)\n",
    "test.to_csv(f\"{dir}/split1/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentid</th>\n",
       "      <th>filename</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000000</td>\n",
       "      <td>0000000.png</td>\n",
       "      <td>a red square is on top of a blue square.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000010</td>\n",
       "      <td>0000001.png</td>\n",
       "      <td>a red square is on top of a blue square.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000020</td>\n",
       "      <td>0000002.png</td>\n",
       "      <td>a red square is on top of a blue square.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000030</td>\n",
       "      <td>0000003.png</td>\n",
       "      <td>a red square is on top of a blue square.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00000040</td>\n",
       "      <td>0000004.png</td>\n",
       "      <td>a red square is on top of a blue square.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sentid     filename                                  sentence\n",
       "0  00000000  0000000.png  a red square is on top of a blue square.\n",
       "0  00000010  0000001.png  a red square is on top of a blue square.\n",
       "0  00000020  0000002.png  a red square is on top of a blue square.\n",
       "0  00000030  0000003.png  a red square is on top of a blue square.\n",
       "0  00000040  0000004.png  a red square is on top of a blue square."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train.reset_index(drop=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1c78c6a4a64a7488841273f70e91fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e028e35df6347329c387264e6bd6e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0853630160448f2909992977b1f0d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17150497d07a4a11bfd11044c74f64e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Take a look at the data split\n",
    "data = load_dataset(f\"{dir}/split1\", split=\"test\")\n",
    "print(len(data))\n",
    "pprint(data[1942])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0000000.png',\n",
      " 'imgid': '0000000',\n",
      " 'layout': 'red is on top of blue.',\n",
      " 'layoutid': '000',\n",
      " 'sentences': [{'imgid': '0000000',\n",
      "                'raw': 'a red square is on top of a blue square.',\n",
      "                'sentid': '00000000'},\n",
      "               {'imgid': '0000000',\n",
      "                'raw': 'a blue square is at the bottom of a red square.',\n",
      "                'sentid': '00000001'}]}\n",
      "10692 10692\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "# Criterion: for the same layout, both descriptions are put in training and\n",
    "#           its opposite layout (with both descriptions) will be put in testing\n",
    "train = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "train.set_index(\"sentid\")\n",
    "test = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "test.set_index(\"sentid\")\n",
    "pairs = json.load(open(f\"{dir}/annotations.json\", \"r\"))[\"data\"]\n",
    "print(len(pairs))\n",
    "pprint(pairs[0])\n",
    "\n",
    "train_pairs, test_pairs = [], []\n",
    "\n",
    "for d in pairs:\n",
    "    current_pair = tuple([w for w in d['layout'].strip()[:-1].split() if w in COLORS])\n",
    "    if current_pair[::-1] in train_pairs:\n",
    "        test_pairs.append(current_pair)\n",
    "        for s in d['sentences']:\n",
    "            row = {\n",
    "                \"sentid\": [s['sentid']],\n",
    "                \"filename\": [d['filename']],\n",
    "                \"sentence\": [s['raw']]\n",
    "            }\n",
    "            test = pd.concat([test, pd.DataFrame(row)])\n",
    "    else:\n",
    "        train_pairs.append(current_pair)\n",
    "        for s in d['sentences']:\n",
    "            row = {\n",
    "                \"sentid\": [s['sentid']],\n",
    "                \"filename\": [d['filename']],\n",
    "                \"sentence\": [s['raw']]\n",
    "            }\n",
    "            row = pd.DataFrame(row)\n",
    "            train = pd.concat([train, pd.DataFrame(row)])\n",
    "    \n",
    "print(len(train), len(test))\n",
    "train.to_csv(f\"{dir}/split2/train.csv\", index=False)\n",
    "test.to_csv(f\"{dir}/split2/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('black', 'cyan'),\n",
      " ('black', 'grey'),\n",
      " ('black', 'khaki'),\n",
      " ('black', 'lime'),\n",
      " ('black', 'orange'),\n",
      " ('black', 'pink'),\n",
      " ('black', 'purple'),\n",
      " ('black', 'yellow'),\n",
      " ('blue', 'black'),\n",
      " ('blue', 'cyan'),\n",
      " ('blue', 'green'),\n",
      " ('blue', 'grey'),\n",
      " ('blue', 'khaki'),\n",
      " ('blue', 'lime'),\n",
      " ('blue', 'orange'),\n",
      " ('blue', 'pink'),\n",
      " ('blue', 'purple'),\n",
      " ('blue', 'yellow'),\n",
      " ('cyan', 'grey'),\n",
      " ('cyan', 'khaki'),\n",
      " ('cyan', 'lime'),\n",
      " ('green', 'black'),\n",
      " ('green', 'cyan'),\n",
      " ('green', 'grey'),\n",
      " ('green', 'khaki'),\n",
      " ('green', 'lime'),\n",
      " ('green', 'orange'),\n",
      " ('green', 'pink'),\n",
      " ('green', 'purple'),\n",
      " ('green', 'yellow'),\n",
      " ('grey', 'lime'),\n",
      " ('khaki', 'grey'),\n",
      " ('khaki', 'lime'),\n",
      " ('orange', 'cyan'),\n",
      " ('orange', 'grey'),\n",
      " ('orange', 'khaki'),\n",
      " ('orange', 'lime'),\n",
      " ('pink', 'cyan'),\n",
      " ('pink', 'grey'),\n",
      " ('pink', 'khaki'),\n",
      " ('pink', 'lime'),\n",
      " ('pink', 'orange'),\n",
      " ('pink', 'purple'),\n",
      " ('pink', 'yellow'),\n",
      " ('purple', 'cyan'),\n",
      " ('purple', 'grey'),\n",
      " ('purple', 'khaki'),\n",
      " ('purple', 'lime'),\n",
      " ('purple', 'orange'),\n",
      " ('red', 'black'),\n",
      " ('red', 'blue'),\n",
      " ('red', 'cyan'),\n",
      " ('red', 'green'),\n",
      " ('red', 'grey'),\n",
      " ('red', 'khaki'),\n",
      " ('red', 'lime'),\n",
      " ('red', 'orange'),\n",
      " ('red', 'pink'),\n",
      " ('red', 'purple'),\n",
      " ('red', 'yellow'),\n",
      " ('yellow', 'cyan'),\n",
      " ('yellow', 'grey'),\n",
      " ('yellow', 'khaki'),\n",
      " ('yellow', 'lime'),\n",
      " ('yellow', 'orange'),\n",
      " ('yellow', 'purple')}\n",
      "-------------------------------------\n",
      "{('black', 'blue'),\n",
      " ('black', 'green'),\n",
      " ('black', 'red'),\n",
      " ('blue', 'red'),\n",
      " ('cyan', 'black'),\n",
      " ('cyan', 'blue'),\n",
      " ('cyan', 'green'),\n",
      " ('cyan', 'orange'),\n",
      " ('cyan', 'pink'),\n",
      " ('cyan', 'purple'),\n",
      " ('cyan', 'red'),\n",
      " ('cyan', 'yellow'),\n",
      " ('green', 'blue'),\n",
      " ('green', 'red'),\n",
      " ('grey', 'black'),\n",
      " ('grey', 'blue'),\n",
      " ('grey', 'cyan'),\n",
      " ('grey', 'green'),\n",
      " ('grey', 'khaki'),\n",
      " ('grey', 'orange'),\n",
      " ('grey', 'pink'),\n",
      " ('grey', 'purple'),\n",
      " ('grey', 'red'),\n",
      " ('grey', 'yellow'),\n",
      " ('khaki', 'black'),\n",
      " ('khaki', 'blue'),\n",
      " ('khaki', 'cyan'),\n",
      " ('khaki', 'green'),\n",
      " ('khaki', 'orange'),\n",
      " ('khaki', 'pink'),\n",
      " ('khaki', 'purple'),\n",
      " ('khaki', 'red'),\n",
      " ('khaki', 'yellow'),\n",
      " ('lime', 'black'),\n",
      " ('lime', 'blue'),\n",
      " ('lime', 'cyan'),\n",
      " ('lime', 'green'),\n",
      " ('lime', 'grey'),\n",
      " ('lime', 'khaki'),\n",
      " ('lime', 'orange'),\n",
      " ('lime', 'pink'),\n",
      " ('lime', 'purple'),\n",
      " ('lime', 'red'),\n",
      " ('lime', 'yellow'),\n",
      " ('orange', 'black'),\n",
      " ('orange', 'blue'),\n",
      " ('orange', 'green'),\n",
      " ('orange', 'pink'),\n",
      " ('orange', 'purple'),\n",
      " ('orange', 'red'),\n",
      " ('orange', 'yellow'),\n",
      " ('pink', 'black'),\n",
      " ('pink', 'blue'),\n",
      " ('pink', 'green'),\n",
      " ('pink', 'red'),\n",
      " ('purple', 'black'),\n",
      " ('purple', 'blue'),\n",
      " ('purple', 'green'),\n",
      " ('purple', 'pink'),\n",
      " ('purple', 'red'),\n",
      " ('purple', 'yellow'),\n",
      " ('yellow', 'black'),\n",
      " ('yellow', 'blue'),\n",
      " ('yellow', 'green'),\n",
      " ('yellow', 'pink'),\n",
      " ('yellow', 'red')}\n"
     ]
    }
   ],
   "source": [
    "pprint(set(train_pairs))\n",
    "print(\"-------------------------------------\")\n",
    "pprint(set(test_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4997165adf5466eaea91937d2c6f4f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bfddd4ab174117a5d77f9f21930ed5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d19b06996b4e45b7294754e3b8f209",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289a78ddd88a4486bbc9813ec414ec04",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0004616.png',\n",
      " 'sentence': 'a yellow square is on top of a blue square.',\n",
      " 'sentid': 46160}\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the data split\n",
    "data = load_dataset(f\"{dir}/split2\", split=\"test\")\n",
    "print(len(data))\n",
    "pprint(data[1942])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0000000.png',\n",
      " 'imgid': '0000000',\n",
      " 'layout': 'red is on top of blue.',\n",
      " 'layoutid': '000',\n",
      " 'sentences': [{'imgid': '0000000',\n",
      "                'raw': 'a red square is on top of a blue square.',\n",
      "                'sentid': '00000000'},\n",
      "               {'imgid': '0000000',\n",
      "                'raw': 'a blue square is at the bottom of a red square.',\n",
      "                'sentid': '00000001'}]}\n",
      "10692 10692\n"
     ]
    }
   ],
   "source": [
    "# Split dataset\n",
    "# Criterion: only \"on top of\" is seen. \"at the bottom of\" is never seen\n",
    "train = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "train.set_index(\"sentid\")\n",
    "test = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "test.set_index(\"sentid\")\n",
    "pairs = json.load(open(f\"{dir}/annotations.json\", \"r\"))[\"data\"]\n",
    "print(len(pairs))\n",
    "pprint(pairs[0])\n",
    "\n",
    "for d in pairs:\n",
    "    for s in d['sentences']:\n",
    "        if 'top' in s['raw']:\n",
    "            row = {\n",
    "                \"sentid\": [s['sentid']],\n",
    "                \"filename\": [d['filename']],\n",
    "                \"sentence\": [s['raw']]\n",
    "            }\n",
    "            row = pd.DataFrame(row)\n",
    "            train = pd.concat([train, pd.DataFrame(row)])\n",
    "        else:\n",
    "            row = {\n",
    "                \"sentid\": [s['sentid']],\n",
    "                \"filename\": [d['filename']],\n",
    "                \"sentence\": [s['raw']]\n",
    "            }\n",
    "            test = pd.concat([test, pd.DataFrame(row)])\n",
    "print(len(train), len(test))\n",
    "\n",
    "train.to_csv(f\"{dir}/impossible_split/train.csv\", index=False)\n",
    "test.to_csv(f\"{dir}/impossible_split/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "859b0909a9c14eb393513a128f847d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "232a0f175370428b83831c3dfec6e9e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e254e5c8cb4fffa4fa4a5dc1f08b61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4753df901ba4d949dba03210220a8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0001942.png',\n",
      " 'sentence': 'a blue square is at the bottom of a green square.',\n",
      " 'sentid': 19421}\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the data split\n",
    "data = load_dataset(f\"{dir}/impossible_split\", split=\"test\")\n",
    "print(len(data))\n",
    "pprint(data[1942])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0000000.png',\n",
      " 'imgid': '0000000',\n",
      " 'layout': 'red is on top of blue.',\n",
      " 'layoutid': '000',\n",
      " 'sentences': [{'imgid': '0000000',\n",
      "                'raw': 'a red square is on top of a blue square.',\n",
      "                'sentid': '00000000'},\n",
      "               {'imgid': '0000000',\n",
      "                'raw': 'a blue square is at the bottom of a red square.',\n",
      "                'sentid': '00000001'}]}\n",
      "10692 10692\n"
     ]
    }
   ],
   "source": [
    "# Split dataset \n",
    "# Criterion: split3 --- similar to split2, but avoid inducing \"position bias\"\n",
    "train = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "train.set_index(\"sentid\")\n",
    "test = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "test.set_index(\"sentid\")\n",
    "pairs = json.load(open(f\"{dir}/annotations.json\", \"r\"))[\"data\"]\n",
    "print(len(pairs))\n",
    "pprint(pairs[0])\n",
    "\n",
    "color2id = {k:i for i, k in enumerate(COLORS.keys())}\n",
    "\n",
    "for d in pairs:\n",
    "    c1, c2 = tuple([w for w in d['layout'].strip()[:-1].split() if w in COLORS])\n",
    "    cid1, cid2 = color2id[c1], color2id[c2]\n",
    "    if 1 <= cid1 - cid2 <= 5 or -11 <= cid1 - cid2 <= -6:\n",
    "        for s in d['sentences']:\n",
    "            row = {\n",
    "                \"sentid\": [s['sentid']],\n",
    "                \"filename\": [d['filename']],\n",
    "                \"sentence\": [s['raw']]\n",
    "            }\n",
    "            row = pd.DataFrame(row)\n",
    "            train = pd.concat([train, pd.DataFrame(row)])\n",
    "    else:\n",
    "        for s in d['sentences']:\n",
    "            row = {\n",
    "                \"sentid\": [s['sentid']],\n",
    "                \"filename\": [d['filename']],\n",
    "                \"sentence\": [s['raw']]\n",
    "            }\n",
    "            test = pd.concat([test, pd.DataFrame(row)])\n",
    "print(len(train), len(test))\n",
    "\n",
    "train.to_csv(f\"{dir}/split3/train.csv\", index=False)\n",
    "test.to_csv(f\"{dir}/split3/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0004956.png',\n",
      " 'sentence': 'a yellow square is on top of a orange square.',\n",
      " 'sentid': 49560}\n"
     ]
    }
   ],
   "source": [
    "# Take a look at the data split\n",
    "data = load_dataset(f\"{dir}/split3\", split=\"test\")\n",
    "print(len(data))\n",
    "pprint(data[4242])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0000000.png',\n",
      " 'imgid': '0000000',\n",
      " 'layout': 'red is on top of blue.',\n",
      " 'layoutid': '000',\n",
      " 'sentences': [{'imgid': '0000000',\n",
      "                'raw': 'a red square is on top of a blue square.',\n",
      "                'sentid': '00000000'},\n",
      "               {'imgid': '0000000',\n",
      "                'raw': 'a blue square is at the bottom of a red square.',\n",
      "                'sentid': '00000001'}]}\n",
      "4860 16524\n"
     ]
    }
   ],
   "source": [
    "# Split dataset \n",
    "# Criterion: split4 --- two relations are learned with two disjoint sets of entities\n",
    "#                   No identity-PoS bias\n",
    "train = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "train.set_index(\"sentid\")\n",
    "test = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "test.set_index(\"sentid\")\n",
    "pairs = json.load(open(f\"{dir}/annotations.json\", \"r\"))[\"data\"]\n",
    "print(len(pairs))\n",
    "pprint(pairs[0])\n",
    "\n",
    "color2id = {k:i for i, k in enumerate(COLORS.keys())}\n",
    "\n",
    "for d in pairs:\n",
    "    c1, c2 = tuple([w for w in d['layout'].strip()[:-1].split() if w in COLORS])\n",
    "    cid1, cid2 = color2id[c1], color2id[c2]\n",
    "    if 0 <= cid1 <= 5 and 0 <= cid2 <= 5:\n",
    "        train_sentence = 0\n",
    "    elif 6 <= cid1 <= 11 and 6 <= cid2 <= 11:\n",
    "        train_sentence = 1\n",
    "    else: \n",
    "        for s in d['sentences']:\n",
    "            row = {\n",
    "                \"sentid\": [s['sentid']],\n",
    "                \"filename\": [d['filename']],\n",
    "                \"sentence\": [s['raw']]\n",
    "            }\n",
    "            test = pd.concat([test, pd.DataFrame(row)])\n",
    "        continue\n",
    "    row = {\n",
    "        \"sentid\": [d['sentences'][train_sentence]['sentid']],\n",
    "        \"filename\": [d['filename']],\n",
    "        \"sentence\": [d['sentences'][train_sentence]['raw']]\n",
    "    }\n",
    "    row = pd.DataFrame(row)\n",
    "    train = pd.concat([train, pd.DataFrame(row)])\n",
    "\n",
    "    test_sentence = 1 - train_sentence\n",
    "    row = {\n",
    "        \"sentid\": [d['sentences'][test_sentence]['sentid']],\n",
    "        \"filename\": [d['filename']],\n",
    "        \"sentence\": [d['sentences'][test_sentence]['raw']]\n",
    "    }\n",
    "    test = pd.concat([test, pd.DataFrame(row)])\n",
    "print(len(train), len(test))\n",
    "\n",
    "train.to_csv(f\"{dir}/split4/train.csv\", index=False)\n",
    "test.to_csv(f\"{dir}/split4/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10692\n",
      "{'filename': '0000000.png',\n",
      " 'imgid': '0000000',\n",
      " 'layout': 'red is on top of blue.',\n",
      " 'layoutid': '000',\n",
      " 'sentences': [{'imgid': '0000000',\n",
      "                'raw': 'a red square is on top of a blue square.',\n",
      "                'sentid': '00000000'},\n",
      "               {'imgid': '0000000',\n",
      "                'raw': 'a blue square is at the bottom of a red square.',\n",
      "                'sentid': '00000001'}]}\n",
      "5832 15552\n"
     ]
    }
   ],
   "source": [
    "# Split dataset \n",
    "# Criterion: split5 --- Identity-Pos bias. \n",
    "#           e.g. Pp - Li are always seen as obj; Rd - Ye are always seen as subj.\n",
    "train = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "train.set_index(\"sentid\")\n",
    "test = pd.DataFrame(columns=[\"sentid\", \"filename\", \"sentence\"])\n",
    "test.set_index(\"sentid\")\n",
    "pairs = json.load(open(f\"{dir}/annotations.json\", \"r\"))[\"data\"]\n",
    "print(len(pairs))\n",
    "pprint(pairs[0])\n",
    "\n",
    "color2id = {k:i for i, k in enumerate(COLORS.keys())}\n",
    "\n",
    "for d in pairs:\n",
    "    c1, c2 = tuple([w for w in d['layout'].strip()[:-1].split() if w in COLORS])\n",
    "    cid1, cid2 = color2id[c1], color2id[c2]\n",
    "    if 0 <= cid1 <= 5 and 6 <= cid2 <= 11:\n",
    "        train_sentence = 0\n",
    "    elif 6 <= cid1 <= 11 and 0 <= cid2 <= 5:\n",
    "        train_sentence = 1\n",
    "    else: \n",
    "        for s in d['sentences']:\n",
    "            row = {\n",
    "                \"sentid\": [s['sentid']],\n",
    "                \"filename\": [d['filename']],\n",
    "                \"sentence\": [s['raw']]\n",
    "            }\n",
    "            test = pd.concat([test, pd.DataFrame(row)])\n",
    "        continue\n",
    "    row = {\n",
    "        \"sentid\": [d['sentences'][train_sentence]['sentid']],\n",
    "        \"filename\": [d['filename']],\n",
    "        \"sentence\": [d['sentences'][train_sentence]['raw']]\n",
    "    }\n",
    "    row = pd.DataFrame(row)\n",
    "    train = pd.concat([train, pd.DataFrame(row)])\n",
    "\n",
    "    test_sentence = 1 - train_sentence\n",
    "    row = {\n",
    "        \"sentid\": [d['sentences'][test_sentence]['sentid']],\n",
    "        \"filename\": [d['filename']],\n",
    "        \"sentence\": [d['sentences'][test_sentence]['raw']]\n",
    "    }\n",
    "    test = pd.concat([test, pd.DataFrame(row)])\n",
    "print(len(train), len(test))\n",
    "\n",
    "train.to_csv(f\"{dir}/split5/train.csv\", index=False)\n",
    "test.to_csv(f\"{dir}/split5/test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
