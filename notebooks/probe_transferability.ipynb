{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, os, re, random\n",
    "import random, time, os, pytz, argparse, yaml, sys\n",
    "#sys.path.append(\"../scripts/probing\")\n",
    "#sys.path.append(\"../scripts\")\n",
    "os.chdir(\"../scripts/probing\")\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "from probing.probe import *\n",
    "from tqdm import tqdm, trange\n",
    "from probing_utils import *\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = \"0921_104304\"\n",
    "with open(f\"ckpts/{handle}/configs.yaml\", 'rb') as f: config = yaml.full_load(f.read()) # dict\n",
    "LM = __import__(config[\"lm\"])\n",
    "tokenizer = LM.get_tokenizer(**config[\"lm_kwargs\"])\n",
    "config[\"lm_kwargs\"][\"token_pos\"] = \"\"\n",
    "\n",
    "model = PROBE(\n",
    "    config['hidden_dim_multipliers'], \n",
    "    len(config['relations'].split()), \n",
    "    config[\"lm\"],\n",
    "    config[\"lm_kwargs\"]\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(f\"ckpts/{handle}/model.pt\"))\n",
    "\n",
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"a balloon is behind a cup\"]\n",
    "input_ids = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_tensors = \"pt\",\n",
    "        padding = True,\n",
    "        truncation = True\n",
    "    ).input_ids\n",
    "\n",
    "encoded_text = model.encode_subj_obj(texts, [],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 8])\n",
      "\n",
      "token            top     bottom  front   behind  inside  outside\n",
      "<|startoftext|>  -0.4917 -0.8844  1.7860  0.0201 -0.4175 -0.1509\n",
      "a</w>             0.1109 -0.4813 -1.1418 -1.2865  2.9243 -0.3061\n",
      "balloon</w>       0.2821  0.3111 -0.2777 -0.2458 -0.0551  0.1729\n",
      "is</w>           -1.1601 -1.4428  3.5731 -0.5875  0.4735 -1.1746\n",
      "behind</w>        0.3331 -3.9804 10.0252 -3.4241 -1.1613 -2.3603\n",
      "a</w>            -0.6350 -0.8396  5.9970 -3.0409  1.3270 -3.5555\n",
      "cup</w>           0.6243 -4.2512 11.6778 -2.2578 -2.8801 -4.6556\n",
      "<|endoftext|>     1.5570 -3.2904  5.4882 -0.1057  0.1612 -5.4092\n"
     ]
    }
   ],
   "source": [
    "x = encoded_text.view(-1, model.text_embed_dim) # batch_size*2, dim\n",
    "x = model.out(model.layers(x)).transpose(0,1)\n",
    "print(x.size()) # batch_size, num_classes\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_ids.tolist()[0])\n",
    "#print(\"\\n{:16s} {:7s} {:7s}\".format(\"token\", \"r\", \"!r\"))\n",
    "#for tok, r, r_ in zip(tokens, x[0], x[1]):\n",
    "#    print(\"{:16s} {:7.4f} {:7.4f}\".format(tok, r.item(), r_.item()))\n",
    "print(\"\\n{:16s} {:7s} {:7s} {:7s} {:7s} {:7s} {:7s}\".format(\"token\", \"top\", \"bottom\", \"front\", \"behind\", \"inside\", \"outside\"))\n",
    "for tok, r0, r1, r2, r3, r4, r5 in zip(tokens, x[0], x[1], x[2], x[3], x[4], x[5]):\n",
    "    print(\"{:16s} {:7.4f} {:7.4f} {:7.4f} {:7.4f} {:7.4f} {:7.4f}\".format(tok, r0.item(), r1.item(), r2.item(), r3.item(), r4.item(), r5.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Does CLIP send information about the correct **relation pair** to nouns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "handle = \"0921_104117\"\n",
    "with open(f\"ckpts/{handle}/configs.yaml\", 'rb') as f: config = yaml.full_load(f.read()) # dict\n",
    "LM = __import__(config[\"lm\"])\n",
    "tokenizer = LM.get_tokenizer(**config[\"lm_kwargs\"])\n",
    "\n",
    "model = PROBE(\n",
    "    config['hidden_dim_multipliers'], \n",
    "    len(config['relations'].split()), \n",
    "    config[\"lm\"],\n",
    "    config[\"lm_kwargs\"]\n",
    ").to(device)\n",
    "model.load_state_dict(torch.load(f\"ckpts/{handle}/model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ood_test_data = Texts(\n",
    "    relations=config['relations'].split(),\n",
    "    nouns_file=config['ood_nouns_file'],\n",
    ")\n",
    "dataloader = DataLoader(ood_test_data, shuffle=True, batch_size=config['batch_size'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:   0%|          | 0/82 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('a towel is at the bottom of a container', 'a blouse is at the bottom of a hook', 'a calender is outside of a hourglass', 'a saddle is outside of a trumpet', 'a miniature is in front of a container', 'a postcard is on top of a screen', 'a jar is outside of a container', 'a hourglass is on top of a trumpet', 'a dresser is on top of a brownie', 'a hourglass is behind a camera', 'a brownie is inside a face', 'a stone is in front of a camera', 'a jar is outside of a scale', 'a face is at the bottom of a container', 'a plant is behind a face', 'a blouse is behind a face', 'a face is in front of a calender', 'a diary is in front of a screen', 'a dryer is outside of a bathtub', 'a bathtub is at the bottom of a scale', 'a bathtub is outside of a rock', 'a dryer is inside a postcard', 'a camera is inside a cable', 'a camera is outside of a head', 'a cable is outside of a scale', 'a dresser is inside a backpack', 'a bathtub is behind a scale', 'a card is inside a calender', 'a miniature is inside a postcard', 'a card is outside of a plant', 'a scale is in front of a container', 'a backpack is inside a towel', 'a backpack is at the bottom of a scale', 'a face is inside a card', 'a scale is in front of a plant', 'a body is on top of a screen', 'a towel is on top of a container', 'a hourglass is outside of a scale', 'a towel is behind a blouse', 'a plant is in front of a hook', 'a blouse is outside of a diary', 'a head is at the bottom of a diary', 'a plant is behind a booklet', 'a hourglass is outside of a card', 'a backpack is outside of a body', 'a screen is on top of a trumpet', 'a plant is at the bottom of a screen', 'a head is in front of a booklet', 'a saddle is at the bottom of a helicopter', 'a hourglass is behind a card', 'a miniature is outside of a dryer', 'a hourglass is at the bottom of a blouse', 'a dresser is inside a saddle', 'a hourglass is outside of a face', 'a dresser is behind a face', 'a saddle is at the bottom of a jar', 'a postcard is in front of a face', 'a head is inside a screen', 'a camera is on top of a scale', 'a rock is inside a diary', 'a booklet is behind a saddle', 'a jar is at the bottom of a blouse', 'a hourglass is on top of a miniature', 'a camera is inside a postcard')\n",
      "tensor([2, 0, 4, 0, 3, 4, 1, 4, 5, 3, 1, 1, 3, 4, 4, 1, 1, 1, 4, 2, 3, 5, 2, 3,\n",
      "        3, 4, 0, 0, 3, 2, 4, 2, 0, 3, 2, 3, 0, 4, 1, 0, 1, 4, 0, 1, 5, 5, 5, 4,\n",
      "        3, 4, 1, 5, 1, 2, 2, 5, 5, 5, 2, 4, 1, 3, 4, 5, 4, 0, 0, 5, 1, 3, 0, 1,\n",
      "        2, 1, 4, 4, 2, 2, 3, 3, 4, 4, 0, 0, 3, 2, 4, 4, 4, 4, 5, 1, 3, 0, 0, 2,\n",
      "        1, 0, 4, 2, 5, 4, 4, 0, 1, 5, 4, 4, 1, 2, 1, 0, 1, 3, 0, 5, 5, 1, 2, 5,\n",
      "        0, 2, 3, 0, 4, 5, 5, 1], device='cuda:0')\n",
      "tensor([1, 0, 1, 0, 5, 4, 5, 4, 2, 3, 0, 1, 5, 4, 0, 1, 0, 1, 3, 2, 4, 5, 2, 3,\n",
      "        5, 4, 1, 0, 3, 2, 3, 2, 2, 3, 2, 3, 5, 4, 1, 0, 5, 4, 4, 5, 4, 5, 5, 4,\n",
      "        5, 4, 4, 5, 3, 2, 4, 5, 4, 5, 5, 4, 2, 3, 4, 5, 1, 0, 4, 5, 2, 3, 0, 1,\n",
      "        0, 1, 5, 4, 3, 2, 2, 3, 5, 4, 1, 0, 3, 2, 5, 4, 5, 4, 0, 1, 1, 0, 2, 3,\n",
      "        1, 0, 3, 2, 5, 4, 1, 0, 4, 5, 5, 4, 3, 2, 1, 0, 2, 3, 4, 5, 0, 1, 4, 5,\n",
      "        3, 2, 1, 0, 0, 1, 4, 5], device='cuda:0')\n",
      "1 0.671875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "lazy_accs = []\n",
    "for (texts, labels) in tqdm(dataloader, desc=\"Testing\"):\n",
    "    output = model(list(texts)) # batch_size*2, num_classes\n",
    "    gth = torch.cat([labels, 1 - (labels % 2) + 2*(labels // 2)], dim=1).long().view((-1,)).to(device)\n",
    "    pred = output.argmax(1, keepdim=True)\n",
    "    print(texts)\n",
    "    print(pred.squeeze())\n",
    "    print(gth)\n",
    "    lazy_accs.append(get_lazy_acc(output, gth).item())\n",
    "    break\n",
    "print(len(lazy_accs), np.mean(lazy_accs))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
