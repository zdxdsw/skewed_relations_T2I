{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../scripts\")\n",
    "import torch\n",
    "from torch import nn\n",
    "import re, json, random\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "pd.set_option('display.float_format', '{:.4f}'.format)\n",
    "from t5 import *\n",
    "from helper import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#t5_name = 't5-small'\n",
    "t5_name = 'google/flan-t5-xxl'\n",
    "t5 = partial(t5_encode_text, name = t5_name, dtype = torch.float32) \n",
    "t5(\"hello world\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2073\n"
     ]
    }
   ],
   "source": [
    "verbs = json.load(open(\"../data/coco_verbs/coco_verbs.json\", \"r\"))['transitive']\n",
    "print(len(verbs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top\n",
      "bottom\n",
      "inside\n",
      "outside\n",
      "front\n",
      "behind\n",
      "empty\n"
     ]
    }
   ],
   "source": [
    "rel_embs = {\n",
    "    \"top\":[],\n",
    "    \"bottom\": [],\n",
    "    \"inside\": [],\n",
    "    \"outside\": [],\n",
    "    \"front\": [],\n",
    "    \"behind\": [],\n",
    "    \"empty\": [],\n",
    "}\n",
    "relations = [\"is on top of\", \"is at the bottom of\", \"is inside\", \"is outside of\", \"is in front of\", \"is behind\", \"and\"]\n",
    "for k, r in zip(rel_embs.keys(), relations):\n",
    "    print(k)\n",
    "    enc = t5(f\"A {r} B\")[0]\n",
    "    rel_embs[k].extend([enc[0], enc[-2]])\n",
    "#relation_embeddings = torch.stack([t5(f\"A {r} B\")[0, :, :] for r in relations])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2073/2073 [01:27<00:00, 23.68it/s]\n"
     ]
    }
   ],
   "source": [
    "# compute v-r scores for all v\n",
    "rel_hats = {\"A\": [], \"B\": []}\n",
    "for v in tqdm(verbs):\n",
    "    enc = t5(f\"A {convert_to_third_person_singular(v)} B\")[0]\n",
    "    rel_hats[\"A\"].append(enc[0]) \n",
    "    rel_hats[\"B\"].append(enc[-2]) \n",
    "#[A, v1, v2, .., B, </s>]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given r, v\n",
    "\n",
    "enc(\"A {r} B\") \n",
    "enc[0] = A_c + A_l\n",
    "enc[-2] = B_c + B_l\n",
    "\n",
    "enc(\"A {v} B\") \n",
    "A_c + A_l'\n",
    "B_c + B_l'\n",
    "\n",
    "v-r score = sim(A_c + A_l, A_c + A_l') + sim(B_c + B_l, B_c + B_l')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(rel_hats, \"../data/llm_preferences_tmp.pt\")\n",
    "#rel_hats = torch.load(\"../data/llm_preferences_tmp.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([7, 2073]) torch.Size([7, 2073])\n",
      "torch.Size([2073, 7])\n"
     ]
    }
   ],
   "source": [
    "simA = cos_sim(torch.stack([v[0] for v in rel_embs.values()]), torch.stack(rel_hats[\"A\"]))\n",
    "simB = cos_sim(torch.stack([v[1] for v in rel_embs.values()]), torch.stack(rel_hats[\"B\"]))\n",
    "print(simA.shape, simB.shape)\n",
    "sim = (simA + simB)\n",
    "#sim = sim - sim[-1]\n",
    "sim = sim.transpose(1,0)\n",
    "print(sim.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1293, 0.1111, 0.1384, 0.1136, 0.1255, 0.1245, 0.0000],\n",
      "       device='cuda:0') tensor([ 0.0129, -0.0022,  0.0654,  0.0486,  0.0140,  0.0719,  0.0000],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "std, mean = torch.std_mean(sim, dim=0)\n",
    "print(std, mean)\n",
    "sim = (sim - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>top</th>\n",
       "      <th>bottom</th>\n",
       "      <th>inside</th>\n",
       "      <th>outside</th>\n",
       "      <th>front</th>\n",
       "      <th>behind</th>\n",
       "      <th>empty</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>verb</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>.hit</th>\n",
       "      <td>0.3657</td>\n",
       "      <td>0.3968</td>\n",
       "      <td>0.4900</td>\n",
       "      <td>0.4570</td>\n",
       "      <td>0.3937</td>\n",
       "      <td>0.4591</td>\n",
       "      <td>0.3356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abandon</th>\n",
       "      <td>0.3529</td>\n",
       "      <td>0.4044</td>\n",
       "      <td>0.4301</td>\n",
       "      <td>0.4538</td>\n",
       "      <td>0.3586</td>\n",
       "      <td>0.4474</td>\n",
       "      <td>0.3017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>aboarde</th>\n",
       "      <td>0.2880</td>\n",
       "      <td>0.3353</td>\n",
       "      <td>0.4085</td>\n",
       "      <td>0.3707</td>\n",
       "      <td>0.3181</td>\n",
       "      <td>0.3560</td>\n",
       "      <td>0.2955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>absorb</th>\n",
       "      <td>0.3782</td>\n",
       "      <td>0.4171</td>\n",
       "      <td>0.4083</td>\n",
       "      <td>0.4669</td>\n",
       "      <td>0.3989</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>0.3450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abuse</th>\n",
       "      <td>0.3180</td>\n",
       "      <td>0.3623</td>\n",
       "      <td>0.4122</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>0.3287</td>\n",
       "      <td>0.4072</td>\n",
       "      <td>0.2802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           top  bottom  inside  outside  front  behind  empty\n",
       "verb                                                         \n",
       ".hit    0.3657  0.3968  0.4900   0.4570 0.3937  0.4591 0.3356\n",
       "abandon 0.3529  0.4044  0.4301   0.4538 0.3586  0.4474 0.3017\n",
       "aboarde 0.2880  0.3353  0.4085   0.3707 0.3181  0.3560 0.2955\n",
       "absorb  0.3782  0.4171  0.4083   0.4669 0.3989  0.4388 0.3450\n",
       "abuse   0.3180  0.3623  0.4122   0.4295 0.3287  0.4072 0.2802"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns=[\"verb\"] + list(rel_embs.keys()))\n",
    "for i, v in enumerate(verbs):\n",
    "    df.loc[i] = [v] + sim[i].tolist()\n",
    "df = df.set_index(['verb'])\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/llm_preferences/t5_xxl_unnormalized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top       0.4127\n",
      "bottom    0.4257\n",
      "inside    0.5402\n",
      "outside   0.4969\n",
      "front     0.4209\n",
      "behind    0.4917\n",
      "empty     0.3735\n",
      "Name: ride, dtype: float64\n",
      "top       0.3450\n",
      "bottom    0.4069\n",
      "inside    0.4226\n",
      "outside   0.4437\n",
      "front     0.3688\n",
      "behind    0.4597\n",
      "empty     0.3013\n",
      "Name: support, dtype: float64\n",
      "top       0.2848\n",
      "bottom    0.3506\n",
      "inside    0.3942\n",
      "outside   0.3848\n",
      "front     0.3089\n",
      "behind    0.3690\n",
      "empty     0.2394\n",
      "Name: inflate, dtype: float64\n",
      "top       0.4009\n",
      "bottom    0.4778\n",
      "inside    0.4425\n",
      "outside   0.5020\n",
      "front     0.4177\n",
      "behind    0.4519\n",
      "empty     0.3470\n",
      "Name: overturn, dtype: float64\n",
      "top       0.3529\n",
      "bottom    0.4096\n",
      "inside    0.4164\n",
      "outside   0.4564\n",
      "front     0.3737\n",
      "behind    0.4359\n",
      "empty     0.2931\n",
      "Name: encompass, dtype: float64\n",
      "top       0.3233\n",
      "bottom    0.3646\n",
      "inside    0.4003\n",
      "outside   0.4240\n",
      "front     0.3338\n",
      "behind    0.4129\n",
      "empty     0.2682\n",
      "Name: wrap, dtype: float64\n",
      "top       0.4779\n",
      "bottom    0.4817\n",
      "inside    0.5000\n",
      "outside   0.5384\n",
      "front     0.4828\n",
      "behind    0.5635\n",
      "empty     0.4420\n",
      "Name: chase, dtype: float64\n",
      "top       0.3890\n",
      "bottom    0.4318\n",
      "inside    0.4713\n",
      "outside   0.4780\n",
      "front     0.3936\n",
      "behind    0.4688\n",
      "empty     0.3388\n",
      "Name: pull, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "for v in [\"ride\", \"support\", \"inflate\", \"overturn\", \"encompass\", \"wrap\", \"chase\", \"pull\",]:\n",
    "    print(df.loc[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'behind': -0.037854984402656555,\n",
      " 'bottom': -0.11444016546010971,\n",
      " 'empty': 0.0,\n",
      " 'front': -0.04939034581184387,\n",
      " 'inside': -0.07742635905742645,\n",
      " 'outside': -0.08330577611923218,\n",
      " 'top': -0.05273474007844925}\n"
     ]
    }
   ],
   "source": [
    "A = \"cat\"\n",
    "B = \"mouse\"\n",
    "v = \"chase\"\n",
    "rel_embs = {\n",
    "    \"top\":[],\n",
    "    \"bottom\": [],\n",
    "    \"inside\": [],\n",
    "    \"outside\": [],\n",
    "    \"front\": [],\n",
    "    \"behind\": [],\n",
    "    \"empty\": [],\n",
    "}\n",
    "relations = [\"is on top of\", \"is at the bottom of\", \"is inside\", \"is outside of\", \"is in front of\", \"is behind\", \"and\"]\n",
    "for k, r in zip(rel_embs.keys(), relations):\n",
    "    enc = t5(f\"{A} {r} {B}\")[0]\n",
    "    rel_embs[k].extend([enc[0], enc[-2]])\n",
    "enc = t5(f\"{A} {convert_to_third_person_singular(v)} {B}\")[0]\n",
    "vr_scores = {}\n",
    "for k, x in rel_embs.items():\n",
    "    vr_scores[k] = cos_sim(x[0], enc[0])[0][0].item() + cos_sim(x[1], enc[1])[0][0].item()\n",
    "for k, v in vr_scores.items():\n",
    "    vr_scores[k] -= vr_scores[\"empty\"]\n",
    "pprint(vr_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A is on top of B\n",
    "C is at the bottom of D\n",
    "\n",
    "A is at the bottom B --> incorrect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "withe\n",
      "6\n",
      "{'behind': tensor([[1.1520]], device='cuda:0'),\n",
      " 'bottom': tensor([[1.1213]], device='cuda:0'),\n",
      " 'empty': tensor([[1.1276]], device='cuda:0'),\n",
      " 'front': tensor([[1.1699]], device='cuda:0'),\n",
      " 'inside': tensor([[1.1858]], device='cuda:0'),\n",
      " 'outside': tensor([[1.1432]], device='cuda:0'),\n",
      " 'top': tensor([[1.1110]], device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "v = random.choice(verbs)\n",
    "print(v)\n",
    "enc = t5(f\"A {convert_to_third_person_singular(v)} B\")[0]\n",
    "print(len(enc))\n",
    "r_A, r_B = enc[0], enc[-2]\n",
    "sim = {}\n",
    "for k, v in rel_embs.items():\n",
    "    sim[k] = cos_sim(r_A, v[0]) + cos_sim(r_B, v[1])\n",
    "pprint(sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 71,  19,  30, 420,  13, 272,   1]])\n",
      "tensor([[  71,   19,   44,    8, 2007,   13,  272,    1]])\n",
      "tensor([[ 71,  11, 272,   1]])\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer('google/flan-t5-xxl', torch.float32)\n",
    "for r in relations:\n",
    "    texts = [f\"A {r} B\"]\n",
    "    encoded = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_tensors = \"pt\",\n",
    "        padding = 'longest',\n",
    "        max_length = MAX_LENGTH,\n",
    "        truncation = True\n",
    "    )\n",
    "    print(encoded.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<pad>', '</s>', '<unk>', '▁', 'X', '.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([0, 1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_tokens_to_ids(['<s>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('google/flan-t5-xxl', torch.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "RELATION_PHRASES = {\n",
    "    'top': \"is on top of\",\n",
    "    'bottom': \"is at the bottom of\",\n",
    "    'front': \"is in front of\",\n",
    "    'behind': \"is behind\",\n",
    "    'inside': \"is inside\",\n",
    "    'outside': \"is outside of\",\n",
    "}\n",
    "texts = list(RELATION_PHRASES.values()) + [\"a\", \"an\"]\n",
    "input_ids = tokenizer.batch_encode_plus(\n",
    "        texts,\n",
    "        return_tensors = \"pt\",\n",
    "        padding = 'longest',\n",
    "        max_length = MAX_LENGTH,\n",
    "        truncation = True\n",
    "    ).input_ids.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[19, 30, 420, 13, 1, 0],\n",
       " [19, 44, 8, 2007, 13, 1],\n",
       " [19, 16, 851, 13, 1, 0],\n",
       " [19, 1187, 1, 0, 0, 0],\n",
       " [19, 1096, 1, 0, 0, 0],\n",
       " [19, 1067, 13, 1, 0, 0],\n",
       " [3, 9, 1, 0, 0, 0],\n",
       " [46, 1, 0, 0, 0, 0]]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$3 9 ', '$46 ']\n",
      "[' 19 30 420 13 3 9 ',\n",
      " ' 19 44 8 2007 13 3 9 ',\n",
      " ' 19 16 851 13 3 9 ',\n",
      " ' 19 1187 3 9 ',\n",
      " ' 19 1096 3 9 ',\n",
      " ' 19 1067 13 3 9 ',\n",
      " ' 19 30 420 13 46 ',\n",
      " ' 19 44 8 2007 13 46 ',\n",
      " ' 19 16 851 13 46 ',\n",
      " ' 19 1187 46 ',\n",
      " ' 19 1096 46 ',\n",
      " ' 19 1067 13 46 ']\n"
     ]
    }
   ],
   "source": [
    "R = []\n",
    "ARTICALS = []\n",
    "for y in input_ids[-2:]:\n",
    "    Y = [str(i) for i in y if i>1]\n",
    "    ARTICALS.append(\"${} \".format(\" \".join(Y)))\n",
    "    for x in input_ids[:-2]:\n",
    "        X = [str(i) for i in x if i>1]\n",
    "        R.append(\" {} \".format(\" \".join(X)) + \"{} \".format(\" \".join(Y)))\n",
    "print(ARTICALS)\n",
    "pprint(R)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4180 2138, 5650 7 [2, 2, 5]\n",
      "4180 5650\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.batch_encode_plus(\n",
    "        [\"a mountaincat is in front of an sofas\"],\n",
    "        return_tensors = \"pt\",\n",
    "        padding = 'longest',\n",
    "        max_length = MAX_LENGTH,\n",
    "        truncation = True\n",
    "    ).input_ids.tolist()\n",
    "x = \"$\" + \" \".join([str(i) for i in input_ids[0] if i>1])\n",
    "offsets = [0, 0, 0]\n",
    "for s in ARTICALS:\n",
    "    if s in x:\n",
    "        x = x.replace(s, \"\")\n",
    "        offsets[0] = len(s.split())\n",
    "        break\n",
    "for s in R:\n",
    "    if s in x:\n",
    "        x = x.replace(s, \", \")\n",
    "        offsets[2] = len(s.split())\n",
    "        break\n",
    "offsets[1] = len(x.split(\", \")[0].split())\n",
    "print(x, offsets)\n",
    "subj_pos, obj_pos = offsets[0], sum(offsets)\n",
    "print(input_ids[0][subj_pos], input_ids[0][obj_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['▁A', '▁cat']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.convert_ids_to_tokens([71, 1712])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
