{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(\"../\")\n",
    "import torch\n",
    "from torch import nn\n",
    "import re\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "from src.t5 import t5_encode_text, get_encoded_dim\n",
    "from src.helper import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process Chatgpt output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "650\n",
      "364\n",
      "['abut', 'adhere', 'adjoin', 'adorn', 'affix', 'align', 'anchor', 'append', 'apply', 'approach', 'arrange', 'arrive', 'ascend', 'attach', 'avoid', 'bake', 'balance', 'bandage', 'base', 'bed', 'bend', 'bind', 'blanket', 'blend', 'block', 'boast', 'boil', 'bolt', 'bounce', 'brace', 'bracket', 'brag', 'break', 'bring', 'broil', 'brush', 'buckle', 'build', 'bundle', 'burn', 'burrow', 'bury', 'button', 'camouflage', 'capsize', 'carry', 'catch', 'cement', 'chase', 'chew', 'cinch', 'clamp', 'clasp', 'climb', 'cling', 'close', 'clothe', 'cluster', 'clutch', 'coat', 'collapse', 'combine', 'compress', 'conceal', 'connect', 'consume', 'cook', 'couple', 'cover', 'cram', 'crawl', 'creep', 'crisscross', 'cross', 'crumble', 'curl', 'curve', 'cut', 'dance', 'dangle', 'decorate', 'deepen', 'delve', 'depose', 'deposit', 'descend', 'devour', 'dig', 'disconnect', 'disguise', 'display', 'dive', 'dock', 'drag', 'drape', 'droop', 'drop', 'drown', 'embed', 'embrace', 'encase', 'encircle', 'enclose', 'encompass', 'engulf', 'enter', 'entomb', 'entrench', 'envelop', 'erode', 'establish', 'excavate', 'exhibit', 'exit', 'extend', 'extract', 'fall', 'fasten', 'feast', 'feature', 'feed', 'fill', 'fix', 'flaunt', 'flip', 'float', 'fly', 'fold', 'follow', 'found', 'fry', 'fuse', 'gather', 'glide', 'glue', 'gobble', 'grab', 'grasp', 'grill', 'grind', 'grip', 'ground', 'group', 'hang', 'heap', 'heel', 'hide', 'hit', 'hitch', 'hook', 'hop', 'hug', 'imbed', 'immerse', 'implant', 'incinerate', 'incline', 'incrust', 'infiltrate', 'infuse', 'ingest', 'insert', 'install', 'integrate', 'interlock', 'intersect', 'intertwine', 'jam', 'join', 'jump', 'kick', 'knock', 'knot', 'lace', 'lash', 'latch', 'lay', 'layer', 'lean', 'leap', 'lie', 'lift', 'link', 'list', 'listen', 'load', 'locate', 'lock', 'lodge', 'loop', 'lower', 'mend', 'merge', 'mix', 'model', 'mound', 'mount', 'move', 'nail', 'navigate', 'needle', 'nestle', 'nibble', 'obscure', 'observe', 'occupy', 'open', 'overlap', 'overlay', 'overturn', 'pack', 'pair', 'parade', 'pass', 'patch', 'peek', 'penetrate', 'perch', 'permeate', 'pile', 'pin', 'place', 'plant', 'plow', 'plunge', 'polish', 'pose', 'position', 'pour', 'present', 'press', 'prop', 'publish', 'pull', 'push', 'put', 'raise', 'reach', 'remove', 'repair', 'rest', 'ride', 'roast', 'roll', 'roost', 'root', 'rotate', 'run', 'sandwich', 'scale', 'scatter', 'scoop', 'scrape', 'screw', 'scrub', 'secure', 'separate', 'set', 'settle', 'sew', 'shake', 'sheathe', 'shelve', 'shift', 'shove', 'show', 'show off', 'showcase', 'simmer', 'sink', 'sit', 'situate', 'skid', 'skip', 'slant', 'slide', 'slip', 'slope', 'smash', 'smooth', 'smother', 'snuggle', 'solder', 'spill', 'spin', 'splice', 'spread', 'sprinkle', 'squash', 'squat', 'squeeze', 'squish', 'stack', 'stage', 'stand', 'staple', 'steam', 'step', 'stick', 'stir', 'stitch', 'stock', 'store', 'stow', 'straddle', 'straighten', 'strap', 'stretch', 'string', 'stuff', 'submerge', 'subside', 'superpose', 'suspend', 'sway', 'swing', 'tack', 'tangle', 'tape', 'tether', 'thread', 'throw', 'thrust', 'tie', 'tilt', 'tip', 'toast', 'topple', 'toss', 'touch', 'trace', 'travel', 'traverse', 'tuck', 'tumble', 'tunnel', 'turn', 'twist', 'unfold', 'unite', 'unpack', 'upend', 'velcro', 'walk', 'wander', 'watch', 'wave', 'wear', 'weave', 'wedge', 'weld', 'whip', 'whirl', 'wiggle', 'wind', 'wipe', 'wrap', 'wreck', 'yank', 'zigzag', 'zip', 'zip-tie', 'zipper', 'zoom']\n"
     ]
    }
   ],
   "source": [
    "verbs = []\n",
    "for file in [\"at_the_bottom_of.txt\", \"on_top_of.txt\", \"entail_spatial_relation.txt\"]:\n",
    "    with open(f\"../data/chatgpt_output/{file}\", \"r\") as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(r\"\\d+\\. (?P<verb>.*)\\b\", line)\n",
    "            if match is not None:\n",
    "                v = match.group('verb')\n",
    "                if len(v): verbs.append(v.lower())\n",
    "print(len(verbs))\n",
    "verbs = list(set(verbs))\n",
    "verbs.sort()\n",
    "print(len(verbs))\n",
    "print(verbs)\n",
    "#with open(\"../data/verbs.txt\", \"w\") as f:\n",
    "    #for v in verbs: f.write(f\"{v}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1254\n",
      "858\n",
      "725\n",
      "['abandon', 'abduct', 'abhor', 'abide', 'absorb', 'abstain', 'accept', 'accompany', 'accuse', 'achieve', 'acquire', 'admire', 'adopt', 'adore', 'advance', 'advertise', 'advise', 'affect', 'agitate', 'aid', 'aim', 'alert', 'allocate', 'allow', 'alter', 'amaze', 'amuse', 'analyze', 'annoy', 'answer', 'anticipate', 'apologize', 'appoint', 'appreciate', 'apprehend', 'approve', 'argue', 'arrest', 'assemble', 'assess', 'assign', 'assist', 'associate', 'assume', 'attract', 'auction', 'authorize', 'award', 'bargain', 'barter', 'beat', 'beg', 'behave', 'belief', 'believe', 'benefit', 'betray', 'blame', 'bless', 'borrow', 'breathe', 'bribe', 'calculate', 'capture', 'care', 'cause', 'celebrate', 'challenge', 'change', 'charge', 'charm', 'cheat', 'check', 'choose', 'claim', 'clean', 'clear', 'collect', 'comfort', 'command', 'communicate', 'compare', 'compel', 'compete', 'complain', 'complete', 'complicate', 'compose', 'compromise', 'conclude', 'condemn', 'conduct', 'confess', 'confront', 'confuse', 'congratulate', 'conquer', 'consider', 'contain', 'control', 'convert', 'convince', 'cooperate', 'copy', 'correct', 'corrupt', 'counsel', 'count', 'create', 'criticize', 'crush', 'cry', 'cure', 'damage', 'dare', 'debate', 'deceive', 'decide', 'declare', 'decrease', 'dedicate', 'defend', 'define', 'delay', 'delight', 'deliver', 'demand', 'demonstrate', 'deny', 'depend', 'describe', 'deserve', 'design', 'destroy', 'detect', 'determine', 'develop', 'devote', 'diagnose', 'dictate', 'differentiate', 'diminish', 'direct', 'disagree', 'disapprove', 'discard', 'discover', 'discuss', 'dislike', 'dispute', 'distract', 'distribute', 'divert', 'divide', 'dominate', 'donate', 'doubt', 'drain', 'draw', 'dream', 'dress', 'drill', 'drive', 'earn', 'eat', 'educate', 'elect', 'elevate', 'eliminate', 'embarrass', 'emphasize', 'employ', 'encourage', 'end', 'endorse', 'enforce', 'engage', 'enhance', 'enjoy', 'enrage', 'ensure', 'entertain', 'envision', 'envy', 'equip', 'escape', 'estimate', 'evaluate', 'examine', 'excel', 'exchange', 'execute', 'exert', 'exhale', 'expand', 'expect', 'explain', 'explore', 'express', 'face', 'facilitate', 'fail', 'fake', 'familiarize', 'fancy', 'fascinate', 'fear', 'feel', 'fetch', 'fight', 'file', 'finance', 'find', 'finish', 'fit', 'fool', 'force', 'forge', 'forgive', 'form', 'formulate', 'foster', 'frame', 'free', 'frighten', 'fulfill', 'generate', 'get', 'give', 'grant', 'greet', 'guarantee', 'guard', 'guide', 'handle', 'harm', 'harvest', 'hate', 'heal', 'hear', 'help', 'highlight', 'hire', 'hold', 'honor', 'host', 'hunt', 'hurt', 'identify', 'ignore', 'illustrate', 'imagine', 'impact', 'impersonate', 'implement', 'imply', 'import', 'impose', 'imprison', 'improve', 'include', 'incorporate', 'increase', 'indicate', 'induce', 'inflame', 'influence', 'inform', 'inherit', 'initiate', 'injure', 'inspect', 'inspire', 'instruct', 'insult', 'intend', 'interact', 'interfere', 'interpret', 'intervene', 'interview', 'introduce', 'invent', 'investigate', 'invite', 'iron', 'irritate', 'isolate', 'issue', 'judge', 'justify', 'keep', 'kidnap', 'kill', 'kiss', 'know', 'label', 'lament', 'land', 'laugh', 'launch', 'lead', 'learn', 'lease', 'leave', 'lend', 'let', 'level', 'light', 'lighten', 'like', 'limit', 'lose', 'love', 'maintain', 'make', 'manage', 'manipulate', 'manufacture', 'marry', 'master', 'matter', 'measure', 'meet', 'mention', 'mimic', 'mislead', 'misplace', 'miss', 'modify', 'monitor', 'motivate', 'murder', 'name', 'need', 'neglect', 'negotiate', 'notice', 'notify', 'nourish', 'nurture', 'object', 'objectify', 'obtain', 'offend', 'offer', 'operate', 'oppose', 'opt', 'order', 'organize', 'overcome', 'oversee', 'overwhelm', 'paint', 'part', 'participate', 'pat', 'pause', 'pay', 'peck', 'perceive', 'perform', 'persuade', 'pick', 'pinch', 'pioneer', 'plague', 'play', 'please', 'point', 'poison', 'portray', 'praise', 'pray', 'predict', 'prepare', 'prescribe', 'preserve', 'prevent', 'print', 'prioritize', 'prize', 'probe', 'process', 'proclaim', 'produce', 'program', 'project', 'promote', 'protect', 'prove', 'provide', 'provoke', 'punish', 'purchase', 'pursue', 'qualify', 'quench', 'question', 'quiet', 'quiz', 'quote', 'rally', 'rank', 'rate', 'rationalize', 'ravage', 'react', 'read', 'realize', 'reassure', 'rebrand', 'rebuild', 'rebuke', 'recall', 'recap', 'receive', 'recharge', 'recognize', 'recommend', 'reconcile', 'record', 'recruit', 'rectify', 'recycle', 'redeem', 'redefine', 'reduce', 'reevaluate', 'refer', 'reflect', 'refuse', 'regain', 'regard', 'regenerate', 'register', 'regret', 'rehearse', 'reinvent', 'reject', 'rejoice', 'relate', 'relax', 'release', 'relieve', 'remain', 'remember', 'remind', 'render', 'renew', 'reorganize', 'reorient', 'repeat', 'replace', 'reply', 'report', 'represent', 'reprimand', 'request', 'require', 'rescue', 'research', 'resemble', 'reserve', 'reside', 'resist', 'resolve', 'respect', 'respond', 'restore', 'restrain', 'resurrect', 'retrieve', 'reverse', 'review', 'revise', 'revive', 'reward', 'rid', 'ridicule', 'ring', 'rinse', 'rip', 'ripple', 'rise', 'risk', 'rob', 'rock', 'round', 'rove', 'rub', 'rule', 'sacrifice', 'saddle', 'safeguard', 'salute', 'sample', 'sanction', 'satisfy', 'saturate', 'save', 'savor', 'say', 'scan', 'scare', 'schedule', 'scold', 'scorn', 'scrutinize', 'search', 'seduce', 'see', 'seek', 'seize', 'select', 'sell', 'send', 'sense', 'sentence', 'serve', 'shadow', 'shape', 'share', 'shave', 'shine', 'shiver', 'shoot', 'shorten', 'shrug', 'shut', 'sign', 'signal', 'silence', 'simplify', 'sing', 'singe', 'sketch', 'slash', 'slay', 'sleep', 'slice', 'slow', 'smear', 'smell', 'smile', 'smite', 'smoke', 'sneak', 'snip', 'snub', 'solve', 'soothe', 'speak', 'specify', 'spell', 'spend', 'splash', 'split', 'spoil', 'sprain', 'spy', 'stabilize', 'stain', 'stamp', 'stare', 'start', 'startle', 'steal', 'stem', 'stifle', 'stimulate', 'stop', 'strain', 'strengthen', 'stress', 'struggle', 'study', 'submit', 'succeed', 'suck', 'suffer', 'suggest', 'summarize', 'summon', 'supply', 'support', 'suppress', 'surprise', 'suspect', 'sustain', 'swallow', 'swarm', 'swear', 'sweep', 'swell', 'swim', 'swindle', 'switch', 'symbolize', 'sympathize', 'tackle', 'take', 'talk', 'tame', 'tap', 'target', 'tax', 'teach', 'tease', 'tell', 'terrorize', 'test', 'thank', 'thicken', 'think', 'threaten', 'thrill', 'thrive', 'thump', 'time', 'tinge', 'tolerate', 'tone', 'torment', 'trade', 'transcribe', 'transfer', 'transform', 'translate', 'transmit', 'transport', 'trap', 'treat', 'trick', 'trim', 'trust', 'try', 'tug', 'type', 'uncover', 'undercut', 'underestimate', 'undergo', 'underlie', 'underline', 'undermine', 'underpin', 'understand', 'understate', 'undertake', 'unify', 'unleash', 'unlock', 'unplug', 'unroll', 'unsettle', 'untangle', 'unwind', 'update', 'uphold', 'upset', 'urge', 'use', 'utilize', 'utter', 'value', 'vanish', 'vary', 'veil', 'venerate', 'vent', 'verify', 'vex', 'view', 'violate', 'visit', 'voice', 'volunteer', 'wage', 'wait', 'wake', 'wane', 'warm', 'warn', 'wash', 'waste', 'wax', 'weed', 'weigh', 'welcome', 'whack', 'wheedle', 'wheeze', 'whiff', 'whimper', 'whipstitch', 'whisk', 'whisker', 'whisper', 'whiten', 'whittle', 'widen', 'widow', 'wield', 'will', 'wilt', 'win', 'winnow', 'withdraw', 'withstand', 'witness', 'wonder', 'woo', 'work', 'worry', 'worship', 'wound', 'wrench', 'wrest', 'wring', 'write', 'yield', 'zap', 'zonk']\n"
     ]
    }
   ],
   "source": [
    "verbs = [l.strip() for l in open(\"../data/verbs.txt\", \"r\").readlines()]\n",
    "\n",
    "general_transitive_verbs = []\n",
    "with open(f\"../data/chatgpt_output/transitive_verbs.txt\", \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        match = re.match(r\"\\d+\\. (?P<verb>.*)\\b\", line)\n",
    "        if match is not None:\n",
    "            v = match.group('verb').strip()\n",
    "            if len(v): general_transitive_verbs.append(v.lower())\n",
    "print(len(general_transitive_verbs))\n",
    "general_transitive_verbs = list(set(general_transitive_verbs))\n",
    "print(len(general_transitive_verbs))\n",
    "complementary_transitive_verbs = list(set(general_transitive_verbs) - set(verbs))\n",
    "complementary_transitive_verbs.sort()\n",
    "print(len(complementary_transitive_verbs))\n",
    "print(complementary_transitive_verbs)\n",
    "#with open(\"../data/complementary_transitive_verbs.txt\", \"w\") as f:\n",
    "#    for v in complementary_transitive_verbs: f.write(f\"{v}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 512])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t5_name = 't5-small'\n",
    "#t5_name = 'google/flan-t5-xxl'\n",
    "t5 = partial(t5_encode_text, name = t5_name, dtype = torch.float32) \n",
    "t5(\"hello world\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A is on top of B\n"
     ]
    }
   ],
   "source": [
    "relations = [\"is on top of\", \"is at the bottom of\"] #, \"has common boundary with\"]\n",
    "relation_embeddings = torch.stack([t5(f\"A {r} B\")[0, 0, :] for r in relations])\n",
    "print(f\"A {relations[0]} B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1089/1089 [00:04<00:00, 270.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B arranges A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "verb_embeddings = []\n",
    "for v in tqdm(verbs+complementary_transitive_verbs):\n",
    "    verb_embeddings.append(t5(f\"B {convert_to_third_person_singular(v)} A\")[0, 0, :])\n",
    "verb_embeddings = torch.stack(verb_embeddings)\n",
    "print(f\"B {convert_to_third_person_singular(verbs[10])} A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a, b, eps=1e-8):\n",
    "    a_n, b_n = a.norm(dim=1)[:, None], b.norm(dim=1)[:, None]\n",
    "    a_norm = a / torch.max(a_n, eps * torch.ones_like(a_n))\n",
    "    b_norm = b / torch.max(b_n, eps * torch.ones_like(b_n))\n",
    "    sim_mt = torch.mm(a_norm, b_norm.transpose(0, 1))\n",
    "    return sim_mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1089, 3])\n",
      "tensor([0.0321, 0.0314, 0.0313], device='cuda:0') tensor([0.6377, 0.6443, 0.6553], device='cuda:0')\n",
      "tensor([[ 0.2911,  0.2994,  0.1782],\n",
      "        [-0.5744, -0.5608, -0.5840],\n",
      "        [ 0.6578,  0.7344,  0.5663],\n",
      "        ...,\n",
      "        [ 0.7240,  0.9933,  1.1877],\n",
      "        [-2.1166, -2.2848, -2.3957],\n",
      "        [-0.5334, -0.4472, -0.3971]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "sim_mt = cos_sim(verb_embeddings, relation_embeddings)\n",
    "print(sim_mt.size())\n",
    "std, mean = torch.std_mean(sim_mt, dim=0)\n",
    "print(std, mean)\n",
    "sim_mt = (sim_mt - mean) / std\n",
    "print(sim_mt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A is on top of B', 'A is at the bottom of B', 'A has common boundary with B']\n",
      "A encases B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1089 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1089/1089 [00:03<00:00, 278.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0448, 0.0463, 0.0448], device='cuda:0') tensor([0.8718, 0.8715, 0.8748], device='cuda:0')\n",
      "torch.Size([1089, 3])\n",
      "['B is on top of A', 'B is at the bottom of A', 'B has common boundary with A']\n",
      "B encases A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1089/1089 [00:03<00:00, 277.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0321, 0.0314, 0.0313], device='cuda:0') tensor([0.6377, 0.6443, 0.6553], device='cuda:0')\n",
      "torch.Size([1089, 3])\n",
      "Strongly prefer 'on top of':  62\n",
      "Strongly prefer 'at the bottom of':  96\n",
      "Always prefer 'on top of':  89\n",
      "Always prefer 'at the bottom of':  117\n"
     ]
    }
   ],
   "source": [
    "print([f\"A {r} B\" for r in relations])\n",
    "# encode relations with dummy subj and obj, i.e. A <rel> B\n",
    "relations = [\"is on top of\", \"is at the bottom of\", \"has common boundary with\"]\n",
    "relation_embeddings = torch.stack([t5(f\"A {r} B\")[0, 0, :] for r in relations])\n",
    "\n",
    "print(f\"A {convert_to_third_person_singular(verbs[100])} B\")\n",
    "# encode verbs with dummy subj and obj, i.e. A <verb> B\n",
    "verb_embeddings = []\n",
    "for v in tqdm(verbs+complementary_transitive_verbs):\n",
    "    verb_embeddings.append(t5(f\"A {convert_to_third_person_singular(v)} B\")[0, 0, :])\n",
    "verb_embeddings = torch.stack(verb_embeddings)\n",
    "\n",
    "# compute embedding similarities\n",
    "sim_mt = cos_sim(verb_embeddings, relation_embeddings)\n",
    "std, mean = torch.std_mean(sim_mt, dim=0)\n",
    "print(std, mean)\n",
    "sim_mt = (sim_mt - mean) / std\n",
    "print(sim_mt.size())\n",
    "\n",
    "print([f\"B {r} A\" for r in relations])\n",
    "print(f\"B {convert_to_third_person_singular(verbs[100])} A\")\n",
    "# encode verbs with subj-obj interchanged, i.e. B <verb> A\n",
    "verb_embeddings = []\n",
    "for v in tqdm(verbs+complementary_transitive_verbs):\n",
    "    verb_embeddings.append(t5(f\"B {convert_to_third_person_singular(v)} A\")[0, 0, :])\n",
    "verb_embeddings = torch.stack(verb_embeddings)\n",
    "\n",
    "# compute embedding similarities\n",
    "sim_mt2 = cos_sim(verb_embeddings, relation_embeddings)\n",
    "std, mean = torch.std_mean(sim_mt2, dim=0)\n",
    "print(std, mean)\n",
    "sim_mt2 = (sim_mt2 - mean) / std\n",
    "print(sim_mt2.size())\n",
    "\n",
    "d = {\n",
    "    \"Strongly prefer 'on top of': \": [],\n",
    "    \"Strongly prefer 'at the bottom of': \": [],\n",
    "    \"Always prefer 'on top of': \": [],\n",
    "    \"Always prefer 'at the bottom of': \": [],\n",
    "}\n",
    "for i, v in enumerate(verbs):\n",
    "    if sim_mt[i][0] > sim_mt[i][1] and sim_mt2[i][0] < sim_mt[i][1]: \n",
    "        d[\"Strongly prefer 'on top of': \"].append(v)\n",
    "    elif sim_mt[i][0] < sim_mt[i][1] and sim_mt2[i][0] > sim_mt[i][1]:\n",
    "        d[\"Strongly prefer 'at the bottom of': \"].append(v)\n",
    "    elif sim_mt[i][0] >= sim_mt[i][1] and sim_mt2[i][0] >= sim_mt[i][1]:\n",
    "        d[\"Always prefer 'on top of': \"].append(v)\n",
    "    elif sim_mt[i][0] <= sim_mt[i][1] and sim_mt2[i][0] <= sim_mt[i][1]:\n",
    "        d[\"Always prefer 'at the bottom of': \"].append(v)\n",
    "\n",
    "for k, v in d.items():\n",
    "    print(k, len(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abut',\n",
       " 'append',\n",
       " 'arrive',\n",
       " 'bind',\n",
       " 'bring',\n",
       " 'carry',\n",
       " 'catch',\n",
       " 'cover',\n",
       " 'cross',\n",
       " 'dance',\n",
       " 'drape',\n",
       " 'embed',\n",
       " 'encircle',\n",
       " 'enclose',\n",
       " 'hitch',\n",
       " 'implant',\n",
       " 'integrate',\n",
       " 'intersect',\n",
       " 'lash',\n",
       " 'lock',\n",
       " 'mix',\n",
       " 'move',\n",
       " 'observe',\n",
       " 'overlap',\n",
       " 'overlay',\n",
       " 'overturn',\n",
       " 'pass',\n",
       " 'permeate',\n",
       " 'pose',\n",
       " 'present',\n",
       " 'prop',\n",
       " 'push',\n",
       " 'ride',\n",
       " 'roast',\n",
       " 'scrub',\n",
       " 'show',\n",
       " 'staple',\n",
       " 'step',\n",
       " 'stock',\n",
       " 'straddle',\n",
       " 'superpose',\n",
       " 'thrust',\n",
       " 'topple',\n",
       " 'upend',\n",
       " 'walk',\n",
       " 'zip-tie',\n",
       " 'zipper']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[\"Strongly prefer 'on top of': \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json.dump(d, open(\"../data/t5_xxl_top-bottom_preference.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create prompts for LLaMA/Vicuna (since they are decoder-only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"Question: Which one of the following spatial relationships between the subject and the object does the verb '{verb}' best entail? \\n\\nOptions: \\nA. subject is on top of object \\nB. subject is at the bottom of object \\n\\nAnswer: \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: Which one of the following spatial relationships between the subject and the object does the verb 'catch' best entail? \n",
      "\n",
      "Options: \n",
      "A. subject is on top of object \n",
      "B. subject is at the bottom of object \n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "filler = {\"verb\": \"catch\"}\n",
    "print(template.format(**filler))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(verbs+complementary_transitive_verbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'../data/feed_decoder_LM/zero_shot.jsonl', 'w') as outfile:\n",
    "\n",
    "    for i, v in enumerate(verbs+complementary_transitive_verbs):\n",
    "        entry = {\n",
    "            \"question_id\": i,\n",
    "            \"text\": template.format(**{\"verb\": v})\n",
    "        }\n",
    "        json.dump(entry, outfile)\n",
    "        outfile.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clevr",
   "language": "python",
   "name": "clevr"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
